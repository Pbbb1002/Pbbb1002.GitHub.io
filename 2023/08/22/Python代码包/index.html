<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-bounce.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.17.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"mac"},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="​                                         基础0-1背包问题（动态规划）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# -*- coding: utf-8 -*-import numpy as">
<meta property="og:type" content="article">
<meta property="og:title" content="Python代码包">
<meta property="og:url" content="http://example.com/2023/08/22/Python%E4%BB%A3%E7%A0%81%E5%8C%85/index.html">
<meta property="og:site_name" content="Pbbb&#39;s Blog">
<meta property="og:description" content="​                                         基础0-1背包问题（动态规划）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# -*- coding: utf-8 -*-import numpy as">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2023-08-21T16:00:00.000Z">
<meta property="article:modified_time" content="2023-09-05T13:16:17.908Z">
<meta property="article:author" content="彭 斌">
<meta property="article:tag" content="编程">
<meta property="article:tag" content="建模">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/2023/08/22/Python%E4%BB%A3%E7%A0%81%E5%8C%85/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://example.com/2023/08/22/Python%E4%BB%A3%E7%A0%81%E5%8C%85/","path":"2023/08/22/Python代码包/","title":"Python代码包"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Python代码包 | Pbbb's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Pbbb's Blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9F%BA%E7%A1%800-1%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98%EF%BC%88%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%EF%BC%89"><span class="nav-number">1.</span> <span class="nav-text">基础0-1背包问题（动态规划）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.</span> <span class="nav-text">动态规划模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.</span> <span class="nav-text">马尔科夫预测模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%88%86%E7%B1%BB"><span class="nav-number">4.</span> <span class="nav-text">神经网络分类</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#ARIMA%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B"><span class="nav-number">5.</span> <span class="nav-text">ARIMA时间序列预测模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#BP%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B"><span class="nav-number">6.</span> <span class="nav-text">BP神经网络模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%8B%9F%E5%90%88%E6%A8%A1%E5%9E%8B"><span class="nav-number">7.</span> <span class="nav-text">拟合模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%9A%E9%A1%B9%E5%BC%8F%E6%8B%9F%E5%90%88"><span class="nav-number">7.1.</span> <span class="nav-text">多项式拟合</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%9D%9E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E6%8B%9F%E5%90%88"><span class="nav-number">8.</span> <span class="nav-text">非多项式拟合</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%99%BA%E8%83%BD%E4%BC%98%E5%8C%96%E4%B9%8B%E7%B2%92%E5%AD%90%E7%BE%A4%E6%A8%A1%E5%9E%8B"><span class="nav-number">9.</span> <span class="nav-text">智能优化之粒子群模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90%E7%AE%97%E6%B3%95"><span class="nav-number">10.</span> <span class="nav-text">主成分分析算法</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B"><span class="nav-number">11.</span> <span class="nav-text">卷积神经网络模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E6%A8%A1%E5%9E%8B"><span class="nav-number">12.</span> <span class="nav-text">支持向量机模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%8F%92%E5%80%BC"><span class="nav-number">13.</span> <span class="nav-text">插值</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%80%E7%BB%B4%E6%8F%92%E5%80%BC"><span class="nav-number">14.</span> <span class="nav-text">一维插值</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%8C%E7%BB%B4%E6%8F%92%E5%80%BC"><span class="nav-number">14.1.</span> <span class="nav-text">二维插值</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%8C%E7%BB%B4%E6%8F%92%E5%80%BC%E7%9A%84%E4%B8%89%E7%BB%B4%E5%B1%95%E7%A4%BA%E6%96%B9%E6%B3%95"><span class="nav-number">14.2.</span> <span class="nav-text">二维插值的三维展示方法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%81%B0%E8%89%B2%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B"><span class="nav-number">15.</span> <span class="nav-text">灰色预测模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%99%BA%E8%83%BD%E4%BC%98%E5%8C%96%E4%B9%8B%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95"><span class="nav-number">16.</span> <span class="nav-text">智能优化之遗传算法</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#TOPSIS%E7%BB%BC%E5%90%88%E8%AF%84%E4%BB%B7%E6%A8%A1%E5%9E%8B"><span class="nav-number">17.</span> <span class="nav-text">TOPSIS综合评价模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="nav-number">18.</span> <span class="nav-text">逻辑回归模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B"><span class="nav-number">19.</span> <span class="nav-text">决策树分类模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%99%BA%E8%83%BD%E4%BC%98%E5%8C%96%E4%B9%8B%E6%A8%A1%E6%8B%9F%E9%80%80%E7%81%AB%E7%AE%97%E6%B3%95"><span class="nav-number">20.</span> <span class="nav-text">智能优化之模拟退火算法</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A8%A1%E7%B3%8A%E7%BB%BC%E5%90%88%E8%AF%84%E4%BB%B7"><span class="nav-number">21.</span> <span class="nav-text">模糊综合评价</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%B1%82%E6%AC%A1%E5%88%86%E6%9E%90%E6%B3%95"><span class="nav-number">22.</span> <span class="nav-text">层次分析法</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B"><span class="nav-number">23.</span> <span class="nav-text">随机森林分类模型</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="彭 斌"
      src="/images/sunflower.jpg">
  <p class="site-author-name" itemprop="name">彭 斌</p>
  <div class="site-description" itemprop="description">难怪我永远怀念飞灰</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">15</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/08/22/Python%E4%BB%A3%E7%A0%81%E5%8C%85/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/sunflower.jpg">
      <meta itemprop="name" content="彭 斌">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Pbbb's Blog">
      <meta itemprop="description" content="难怪我永远怀念飞灰">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Python代码包 | Pbbb's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Python代码包
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-08-22 00:00:00" itemprop="dateCreated datePublished" datetime="2023-08-22T00:00:00+08:00">2023-08-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-09-05 21:16:17" itemprop="dateModified" datetime="2023-09-05T21:16:17+08:00">2023-09-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Python/" itemprop="url" rel="index"><span itemprop="name">Python</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Python/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/" itemprop="url" rel="index"><span itemprop="name">数学建模</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>15k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>53 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>​                                        <!-- 展开全文 --></p>
<h1 id="基础0-1背包问题（动态规划）"><a href="#基础0-1背包问题（动态规划）" class="headerlink" title="基础0-1背包问题（动态规划）"></a>基础0-1背包问题（动态规划）</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment">#0-1背包算法</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">knapsack</span>(<span class="params">v,w,n,capacity</span>):</span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    capacity = capacity +<span class="number">1</span>   <span class="comment">#初始化背包容量最大值</span></span><br><span class="line">    m = np.zeros((n,capacity))  <span class="comment">#初始化</span></span><br><span class="line">    x = np.zeros(n)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(capacity):</span><br><span class="line">            <span class="keyword">if</span> (j &gt;= w[i]):</span><br><span class="line">                m[i][j] = <span class="built_in">max</span>(m[i - <span class="number">1</span>][j], m[i - <span class="number">1</span>][j - w[i]] + v[i])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                m[i][j] = m[i - <span class="number">1</span>][j]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;动态规划装载表:\n&#x27;</span>,m)</span><br><span class="line">    capacity = capacity -<span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n-<span class="number">1</span>, <span class="number">0</span>, -<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">if</span> (m[i][capacity] == m[i - <span class="number">1</span>][capacity]):</span><br><span class="line">            x[i] = <span class="number">0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            x[i] = <span class="number">1</span></span><br><span class="line">            capacity -= w[i]</span><br><span class="line">    x[<span class="number">0</span>] =<span class="number">1</span> <span class="keyword">if</span> (m[<span class="number">1</span>][capacity] &gt; <span class="number">0</span>) <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    weight = <span class="number">0</span></span><br><span class="line">    value = <span class="number">0</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;装载的物品编号为：&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(x)):</span><br><span class="line">        <span class="keyword">if</span>(x[i] == <span class="number">1</span>):</span><br><span class="line">            weight = weight + w[i]</span><br><span class="line">            value = value +v[i]</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27; &#x27;</span>,i+<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;装载的物品重量为：&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(weight)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;装入的物品价值为：&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(value)</span><br><span class="line">    <span class="keyword">return</span> m</span><br><span class="line"></span><br><span class="line">file_name = [<span class="string">&#x27;input_assgin02_01.dat&#x27;</span>,<span class="string">&#x27;input_assgin02_02.dat&#x27;</span>,<span class="string">&#x27;input_assgin02_03.dat&#x27;</span>,</span><br><span class="line">             <span class="string">&#x27;input_assgin02_04.dat&#x27;</span>,<span class="string">&#x27;input_assgin02_05.dat&#x27;</span>]</span><br><span class="line"><span class="comment">#循环读取文件数据</span></span><br><span class="line"><span class="keyword">for</span> file_name <span class="keyword">in</span> file_name:</span><br><span class="line">	a = np.loadtxt(file_name)</span><br><span class="line">	n = <span class="built_in">int</span>( a[<span class="number">0</span>][<span class="number">0</span>] )    <span class="comment">#读取物品数量</span></span><br><span class="line">	capacity = <span class="built_in">int</span> ( a[<span class="number">0</span>][<span class="number">1</span>] )</span><br><span class="line">	<span class="built_in">print</span>(<span class="string">&#x27;#######################&#x27;</span>)</span><br><span class="line">	<span class="built_in">print</span> (<span class="string">&#x27;&#123;0&#125;文件中的测试结果：&#x27;</span>.<span class="built_in">format</span>(file_name))</span><br><span class="line">	<span class="built_in">print</span>(<span class="string">&#x27;物品数量为：\n&#x27;</span>,n,<span class="string">&#x27;\n背包载重量为：\n&#x27;</span>,capacity)</span><br><span class="line">	w = [<span class="number">0</span>] * n    <span class="comment">#初始化物品重量列表</span></span><br><span class="line">	value = [<span class="number">0</span>] * n    <span class="comment">#初始化物品价值列表</span></span><br><span class="line">	a = np.loadtxt(file_name, skiprows = <span class="number">1</span>, dtype = <span class="built_in">int</span>) </span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):  </span><br><span class="line">		w[i] = <span class="built_in">int</span> ( a[i][<span class="number">0</span>] )    <span class="comment">#读取物品重量列表</span></span><br><span class="line">		value[i] = <span class="built_in">int</span> ( a[i][<span class="number">1</span>] )    <span class="comment">#读取物品价值列表</span></span><br><span class="line">	<span class="built_in">print</span>(<span class="string">&#x27;物品的重量列表为：\n&#x27;</span>, w,<span class="string">&#x27;\n物品的价值列表为：\n&#x27;</span>, value)</span><br><span class="line">	knapsack(value, w, n, capacity)</span><br><span class="line">os.system(<span class="string">&#x27;pause&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="动态规划模型"><a href="#动态规划模型" class="headerlink" title="动态规划模型"></a>动态规划模型</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pylab <span class="keyword">as</span> pl</span><br><span class="line"><span class="keyword">import</span> connmysql</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">sql2 = <span class="string">&quot;SELECT ﻿id, distance,duration FROM  trafic&quot;</span></span><br><span class="line">checklist = connmysql.getdata(sql2)</span><br><span class="line">ids=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="built_in">len</span>(checklist)):</span><br><span class="line">    ids.append(checklist[i][<span class="number">0</span>])</span><br><span class="line">time_dataframe = pd.DataFrame(columns=[<span class="string">&#x27;distance&#x27;</span>,<span class="string">&#x27;duration&#x27;</span>], index=ids)</span><br><span class="line"><span class="comment"># print(time_dataframe)</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="built_in">len</span>(checklist)):</span><br><span class="line">    <span class="built_in">id</span>=checklist[i][<span class="number">0</span>]</span><br><span class="line">    time_dataframe.at[ids[i],<span class="string">&#x27;distance&#x27;</span>] = <span class="built_in">float</span>(checklist[i][<span class="number">1</span>])<span class="comment">#distance</span></span><br><span class="line">    time_dataframe.at[ids[i], <span class="string">&#x27;duration&#x27;</span>] = <span class="built_in">float</span>(checklist[i][<span class="number">2</span>] ) <span class="comment"># distance</span></span><br><span class="line"><span class="comment"># id=&#x27;100001-100002&#x27;</span></span><br><span class="line"><span class="comment"># print(time_dataframe.at[id,&#x27;distance&#x27;])</span></span><br><span class="line"><span class="comment"># print(time_dataframe.at[&#x27;100001-100002&#x27;,&#x27;duration&#x27;])</span></span><br><span class="line"><span class="comment"># list=[&#x27;100002&#x27;,&#x27;100003&#x27;,&#x27;100004&#x27;,&#x27;100005&#x27;,&#x27;100006&#x27;]</span></span><br><span class="line">        <span class="comment">#基于动态规划求得最短路径，计算量会比较小，速度较快</span></span><br><span class="line"><span class="built_in">list</span> = [<span class="string">&#x27;100002&#x27;</span>, <span class="string">&#x27;100003&#x27;</span>, <span class="string">&#x27;100004&#x27;</span>, <span class="string">&#x27;100005&#x27;</span>, <span class="string">&#x27;100006&#x27;</span>]</span><br><span class="line"><span class="comment"># 基于动态规划求得最短路径，计算量会比较小，速度较快</span></span><br><span class="line">routelist=[]</span><br><span class="line">route_distance=[]</span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="built_in">len</span>(<span class="built_in">list</span>)-<span class="number">1</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;mm&#x27;</span>,j)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;he1&#x27;</span>, routelist)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;he2&#x27;</span>, route_distance)</span><br><span class="line">    ids = []</span><br><span class="line">    distances, routes = &#123;&#125;, &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(<span class="built_in">list</span>)):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(routelist)==<span class="number">0</span>:<span class="comment">#当里面还没有目标在时</span></span><br><span class="line">            <span class="built_in">id</span> = <span class="built_in">list</span>[<span class="number">0</span>] + <span class="string">&#x27;-&#x27;</span>+<span class="built_in">list</span>[i]</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">list</span>[i]!=<span class="built_in">list</span>[<span class="number">0</span>]:</span><br><span class="line">                ids.append(<span class="built_in">id</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">list</span>[i] <span class="keyword">not</span> <span class="keyword">in</span> routelist :<span class="comment">#计算过的点不再重复计算</span></span><br><span class="line">                <span class="built_in">id</span> =  routelist[j]+ <span class="string">&#x27;-&#x27;</span>+<span class="built_in">list</span>[i]</span><br><span class="line">                ids.append(<span class="built_in">id</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;he3&#x27;</span>,ids)</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(ids)):</span><br><span class="line">        distances[ids[k]] = time_dataframe.at[ids[k], <span class="string">&#x27;distance&#x27;</span>]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;he4&#x27;</span>,distances)</span><br><span class="line">    route1 = <span class="built_in">sorted</span>(distances.items(), key=<span class="keyword">lambda</span> item: item[<span class="number">1</span>])  <span class="comment"># 将最小距离取出来</span></span><br><span class="line">    route_distance.append(route1[<span class="number">0</span>])</span><br><span class="line">    <span class="comment"># routes[route1[0][0]] = route1[0][1]  # key:100002-100006,values: 3929.0,,保存离最后一个点的最优路线</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;he5&#x27;</span>,route1)</span><br><span class="line">    a=route1[<span class="number">0</span>][<span class="number">0</span>].split(<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> a[<span class="number">0</span>] <span class="keyword">not</span> <span class="keyword">in</span> routelist:</span><br><span class="line">        routelist.append(a[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">if</span> a[<span class="number">1</span>] <span class="keyword">not</span> <span class="keyword">in</span> routelist:</span><br><span class="line">        routelist.append(a[<span class="number">1</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;he6&#x27;</span>, routelist)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;he&#x27;</span>,routelist)</span><br></pre></td></tr></table></figure>

<h1 id="马尔科夫预测模型"><a href="#马尔科夫预测模型" class="headerlink" title="马尔科夫预测模型"></a>马尔科夫预测模型</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#https://github.com/hmmlearn/hmmlearn</span></span><br><span class="line"><span class="comment">#hmm包</span></span><br><span class="line"><span class="comment">#来源于https://blog.csdn.net/xinfeng2005/article/details/53939192</span></span><br><span class="line"><span class="keyword">from</span> hmmlearn.hmm <span class="keyword">import</span> GaussianHMM</span><br><span class="line"><span class="keyword">from</span> hmmlearn.hmm <span class="keyword">import</span> MultinomialHMM</span><br><span class="line"><span class="comment">#GaussianHMM是针对观测为连续，所以观测矩阵B由各个隐藏状态对应观测状态的高斯分布概率密度函数参数来给出</span></span><br><span class="line"><span class="comment">#对应GMMHMM同样，而multinomialHMM是针对离散观测，B可以直接给出</span></span><br><span class="line"></span><br><span class="line"><span class="comment">############################################博客实例#######################</span></span><br><span class="line"><span class="comment">#观测状态是二维，而隐藏状态有4个。</span></span><br><span class="line"><span class="comment">#因此我们的“means”参数是4×24×2的矩阵，而“covars”参数是4×2×24×2×2的张量</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">startprob=np.array([<span class="number">0.6</span>, <span class="number">0.3</span>, <span class="number">0.1</span>, <span class="number">0.0</span>])</span><br><span class="line"><span class="comment">#这里1,3之间无转移可能，对应矩阵为0？</span></span><br><span class="line">transmat=np.array([[<span class="number">0.7</span>, <span class="number">0.2</span>, <span class="number">0.0</span>, <span class="number">0.1</span>],</span><br><span class="line">                     [<span class="number">0.3</span>, <span class="number">0.5</span>, <span class="number">0.2</span>, <span class="number">0.0</span>],</span><br><span class="line">                     [<span class="number">0.0</span>, <span class="number">0.3</span>, <span class="number">0.5</span>, <span class="number">0.2</span>],</span><br><span class="line">                     [<span class="number">0.2</span>, <span class="number">0.0</span>, <span class="number">0.2</span>, <span class="number">0.6</span>]])</span><br><span class="line"><span class="comment">#隐藏状态（component）高斯分布均值？The means of each component</span></span><br><span class="line">means=np.array([[<span class="number">0.0</span>,  <span class="number">0.0</span>],</span><br><span class="line">                  [<span class="number">0.0</span>, <span class="number">11.0</span>],</span><br><span class="line">                  [<span class="number">9.0</span>, <span class="number">10.0</span>],</span><br><span class="line">                  [<span class="number">11.0</span>, -<span class="number">1.0</span>]])</span><br><span class="line"><span class="comment">#隐藏状态协方差The covariance of each component</span></span><br><span class="line">covars=<span class="number">.5</span>*np.tile(np.identity(<span class="number">2</span>),(<span class="number">4</span>,<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line"><span class="comment">#np.tile(x,(n,m)),将x延第一个轴复制n个出来，再延第二个轴复制m个出来。上面，为1*2*2，复制完了就是4*2*2</span></span><br><span class="line"><span class="comment">#np.identity(n)获取n维单位方阵，np.eye(n.m.k)获取n行m列对角元素偏移k的单位阵</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># hmm=GaussianHMM(n_components=4,</span></span><br><span class="line"><span class="comment"># 参数covariance_type，为&quot;full&quot;:所有的μ,Σ都需要指定。取值为“spherical”则Σ的非对角线元素为0，对角线元素相同。取值为“diag”则Σ的非对角线元素为0，对角线元素可以不同，&quot;tied&quot;指所有的隐藏状态对应的观测状态分布使用相同的协方差矩阵Σ</span></span><br><span class="line"><span class="comment">#                 covariance_type=&#x27;full&#x27;,</span></span><br><span class="line"><span class="comment">#                 startprob_prior=1.0,#PI</span></span><br><span class="line"><span class="comment">#                 transmat_prior=1.0,#状态转移A</span></span><br><span class="line"><span class="comment">#                 means_prior=,#“means”用来表示各个隐藏状态对应的高斯分布期望向量μ形成的矩阵</span></span><br><span class="line"><span class="comment">#                 means_weight=,</span></span><br><span class="line"><span class="comment">#                 covars_prior=,#“covars”用来表示各个隐藏状态对应的高斯分布协方差矩阵Σ形成的三维张量</span></span><br><span class="line"><span class="comment">#                 covars_weight=,</span></span><br><span class="line"><span class="comment">#                 algorithm=,</span></span><br><span class="line"><span class="comment">#                 )</span></span><br><span class="line">hmm=GaussianHMM(n_components=<span class="number">4</span>,covariance_type=<span class="string">&#x27;full&#x27;</span>)</span><br><span class="line"><span class="comment">#Instead of fitting it from the data, we directly set the estimated parameters, the means and covariance of the components</span></span><br><span class="line">hmm.startprob_=startprob</span><br><span class="line">hmm.transmat_=transmat</span><br><span class="line">hmm.means_=means</span><br><span class="line">hmm.covars_=covars</span><br><span class="line"><span class="comment">########以上，构建（训练）好了HMM模型（这里没有训练直接给定参数，需要训练则fit）</span></span><br><span class="line"><span class="comment">#观测状态二维，使用三维观测序列，输入3*2*2张量</span></span><br><span class="line">seen = np.array([[<span class="number">1.1</span>,<span class="number">2.0</span>],[-<span class="number">1</span>,<span class="number">2.0</span>],[<span class="number">3</span>,<span class="number">7</span>]])</span><br><span class="line">logprob, state = hmm.decode(seen, algorithm=<span class="string">&quot;viterbi&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(state)</span><br><span class="line"><span class="comment">#HMM问题1对数概率计算</span></span><br><span class="line"><span class="built_in">print</span>(hmm.score(seen))</span><br></pre></td></tr></table></figure>

<h1 id="神经网络分类"><a href="#神经网络分类" class="headerlink" title="神经网络分类"></a>神经网络分类</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#encoding:utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Perceptron</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        eta:学习率</span></span><br><span class="line"><span class="string">        n_iter:权重向量训练的次数</span></span><br><span class="line"><span class="string">        w_：神经分叉权重向量</span></span><br><span class="line"><span class="string">        errors_：用于记录神经元判断出错的次数</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, eta = <span class="number">0.01</span>, n_iter = <span class="number">10</span></span>):</span><br><span class="line">        self.eta = eta</span><br><span class="line">        self.n_iter = n_iter</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">net_input</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">            做点积运算</span></span><br><span class="line"><span class="string">            z = W0*1 + W1*X1 +.... Wn*Xn</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> np.dot(X, self.w_[<span class="number">1</span>:]) + self.w_[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="keyword">return</span> np.where(self.net_input(X) &gt;= <span class="number">0.0</span>, <span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        输入训练数据，培训神经元</span></span><br><span class="line"><span class="string">        x 输入样本向量， y对应的样本分类</span></span><br><span class="line"><span class="string">        x shape[n_samples, n_features]</span></span><br><span class="line"><span class="string">        x:[[1, 2, 3], [4, 5, 6]]</span></span><br><span class="line"><span class="string">        x.shape[1] = 2; x.shape[2] = 3</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, X, y</span>):</span><br><span class="line">        <span class="comment"># 初始化权重为0 加一是因为步调函数阈值</span></span><br><span class="line">        self.w_ = np.zeros(<span class="number">1</span> + X.shape[<span class="number">1</span>])</span><br><span class="line">        self.errors_ = []</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(self.n_iter):</span><br><span class="line">            errors = <span class="number">0</span></span><br><span class="line">           </span><br><span class="line">            <span class="keyword">for</span> xi, target <span class="keyword">in</span> <span class="built_in">zip</span>(X, y):</span><br><span class="line">                <span class="comment"># update =η * (y - y&#x27;)</span></span><br><span class="line">                update = self.eta * (target - self.predict(xi))</span><br><span class="line">                </span><br><span class="line">                <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">                xi是一个向量</span></span><br><span class="line"><span class="string">                update * xi 等价：</span></span><br><span class="line"><span class="string">                [▽W(1) = X[1]*update, ▽w(2) = X[2]*update, ▽w(3) = X[3]*update]</span></span><br><span class="line"><span class="string">                &quot;&quot;&quot;</span></span><br><span class="line">                </span><br><span class="line">                self.w_[<span class="number">1</span>:] += update * xi</span><br><span class="line">                self.w_[<span class="number">0</span>] += update</span><br><span class="line">                errors += <span class="built_in">int</span>(update != <span class="number">0.0</span>)</span><br><span class="line">                self.errors_.append(errors)</span><br><span class="line">    </span><br><span class="line">                <span class="keyword">pass</span></span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_decision_regions</span>(<span class="params">x, y, classifier, resolution = <span class="number">0.02</span></span>):</span><br><span class="line">    marker = (<span class="string">&#x27;s&#x27;</span>, <span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;o&#x27;</span>, <span class="string">&#x27;v&#x27;</span>)</span><br><span class="line">    colors = (<span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;green&#x27;</span>, <span class="string">&#x27;gray&#x27;</span>, <span class="string">&#x27;gray&#x27;</span>, <span class="string">&#x27;cyan&#x27;</span>)</span><br><span class="line">    cmap = ListedColormap(colors[:<span class="built_in">len</span>(np.unique(y))])</span><br><span class="line"></span><br><span class="line">    x1_min, x1_max = x[: , <span class="number">0</span>].<span class="built_in">min</span>() - <span class="number">1</span>, x[: , <span class="number">0</span>].<span class="built_in">max</span>()</span><br><span class="line">    x2_min, x2_max = x[: , <span class="number">1</span>].<span class="built_in">min</span>() - <span class="number">1</span>, x[: , <span class="number">1</span>].<span class="built_in">max</span>()</span><br><span class="line">    <span class="comment">#print x1_min, x1_max, x2_min, x2_max</span></span><br><span class="line">    <span class="comment"># 185 从3.3- 6.98 每隔0.02</span></span><br><span class="line">    <span class="comment"># 255 从0  - 5.08 每隔0.02</span></span><br><span class="line">    <span class="comment"># xx1   从3.3 - 6.98 为一行  有185行相同的数据</span></span><br><span class="line">    <span class="comment"># xx2   从0   - 5.08 为一列  第一行全为0 第二行全1 (255, 185)</span></span><br><span class="line">    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),</span><br><span class="line">                           np.arange(x2_min, x2_max, resolution))</span><br><span class="line">    <span class="comment"># print np.arange(x1_min, x1_max, resolution).shape</span></span><br><span class="line">    <span class="comment"># print np.arange(x1_min, x1_max, resolution)</span></span><br><span class="line">    <span class="comment"># print np.arange(x2_min, x2_max, resolution).shape</span></span><br><span class="line">    <span class="comment"># print np.arange(x2_min, x2_max, resolution)</span></span><br><span class="line">    <span class="comment"># print xx2.shape</span></span><br><span class="line">    <span class="comment"># print xx2</span></span><br><span class="line">    <span class="comment"># 相当于 np.arange(x1_min, x1_max, resolution) np.arange(x2_min, x2_max, resolution)</span></span><br><span class="line">    <span class="comment"># 已经在分类了站如果是3.3 0 则为1 6.94 5.08 则-1</span></span><br><span class="line">    z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)</span><br><span class="line">    <span class="built_in">print</span>(xx1.ravel())</span><br><span class="line">    <span class="built_in">print</span>(xx2.ravel())</span><br><span class="line">    <span class="built_in">print</span>(z)</span><br><span class="line"></span><br><span class="line">    z = z.reshape(xx1.shape)</span><br><span class="line">    <span class="built_in">print</span>(z)</span><br><span class="line">    <span class="comment"># 在两个分类之间画分界线</span></span><br><span class="line">    plt.contourf(xx1, xx2, z, alpha = <span class="number">0.4</span>, cmap = cmap)</span><br><span class="line">    plt.xlim(x1_min, x1_max)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;xx1.min()&quot;</span>, x1_min)</span><br><span class="line">    plt.ylim(xx2.<span class="built_in">min</span>(), xx2.<span class="built_in">max</span>())</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;length of the huajing&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;length of the huaban&#x27;</span>)</span><br><span class="line">    plt.legend(loc=<span class="string">&#x27;upper right&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="comment">## X = np.array([[1, 2, 3], [4, 5, 6]])</span></span><br><span class="line">    <span class="comment"># print X.shape</span></span><br><span class="line">    <span class="comment">## y = [1, -1]</span></span><br><span class="line">    df = pd.read_csv(<span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span>, header = <span class="literal">None</span>)</span><br><span class="line">    <span class="comment">## print df.head(10)</span></span><br><span class="line">    y = df.loc[<span class="number">0</span>:<span class="number">100</span>, <span class="number">4</span>].values</span><br><span class="line">    y = np.where(y == <span class="string">&#x27;Iris-setosa&#x27;</span>, <span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">    x = df.iloc[<span class="number">0</span>:<span class="number">100</span>, [<span class="number">0</span>, <span class="number">2</span>]].values</span><br><span class="line">    plt.scatter(x[:<span class="number">50</span>, <span class="number">0</span>], x[:<span class="number">50</span>, <span class="number">1</span>], color = <span class="string">&#x27;red&#x27;</span>, marker = <span class="string">&#x27;o&#x27;</span>, label = <span class="string">&#x27;setosa&#x27;</span>)</span><br><span class="line">    plt.scatter(x[<span class="number">50</span>:<span class="number">100</span>, <span class="number">0</span>], x[<span class="number">50</span>:<span class="number">100</span>, <span class="number">1</span>], color=<span class="string">&#x27;blue&#x27;</span>, marker=<span class="string">&#x27;*&#x27;</span>, label=<span class="string">&#x27;versicolor&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;length of the huajing&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;length of the huaban&#x27;</span>)</span><br><span class="line">    plt.legend(loc = <span class="string">&#x27;upper right&#x27;</span>)</span><br><span class="line">    <span class="comment"># plt.show()</span></span><br><span class="line">    p1 = Perceptron(eta = <span class="number">0.1</span>)</span><br><span class="line">    p1.fit(x, y)</span><br><span class="line">    <span class="comment"># plt.plot(range(1, len(p1.errors_) + 1), p1.errors_, marker = &#x27;o&#x27;)</span></span><br><span class="line">    <span class="comment"># plt.xlabel(&#x27;Epochs&#x27;)</span></span><br><span class="line">    <span class="comment"># plt.ylabel(&#x27;error sort&#x27;)</span></span><br><span class="line">    <span class="comment"># plt.show()</span></span><br><span class="line">    plot_decision_regions(x, y, p1)</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<h1 id="ARIMA时间序列预测模型"><a href="#ARIMA时间序列预测模型" class="headerlink" title="ARIMA时间序列预测模型"></a>ARIMA时间序列预测模型</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas </span><br><span class="line"> </span><br><span class="line"><span class="comment"># 读取数据，指定日期为索引列 </span></span><br><span class="line">data = pandas.read_csv(</span><br><span class="line">    <span class="string">&#x27;D:\\DATA\\pycase\\number2\\9.3\\Data.csv&#x27;</span> ,</span><br><span class="line">    index_col=<span class="string">&#x27;日期&#x27;</span></span><br><span class="line">)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 绘图过程 </span></span><br><span class="line"><span class="keyword">import</span>  matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 用来正常显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>]=[<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 用来正常显示负号</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span> </span><br><span class="line"> </span><br><span class="line"><span class="comment"># 查看趋势图</span></span><br><span class="line">data.plot() <span class="comment">#有增长趋势，不平稳</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 附加：查看自相关系数合片自相关系数（查分之后），可以用于平稳性的检测，也可用于定阶系数预估</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">#自相关图（）</span></span><br><span class="line"><span class="keyword">from</span> statsmodels.graphics.tsaplots <span class="keyword">import</span> plot_acf</span><br><span class="line"> </span><br><span class="line">plot_acf(data).show() <span class="comment">#自相关图既不是拖尾也不是截尾。以上的图的自相关是一个三角对称的形式，这种趋势是单调趋势的典型图形，说明这个序列不是平稳序列</span></span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="comment"># 1 平稳性检测 </span></span><br><span class="line"><span class="keyword">from</span> statsmodels.tsa.stattools <span class="keyword">import</span> adfuller <span class="keyword">as</span> ADF</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tagADF</span>(<span class="params">t</span>):</span><br><span class="line">    result = pandas.DataFrame(index=[</span><br><span class="line">            <span class="string">&quot;Test Statistic Value&quot;</span>, <span class="string">&quot;p-value&quot;</span>, <span class="string">&quot;Lags Used&quot;</span>, </span><br><span class="line">            <span class="string">&quot;Number of Observations Used&quot;</span>, </span><br><span class="line">            <span class="string">&quot;Critical Value(1%)&quot;</span>, <span class="string">&quot;Critical Value(5%)&quot;</span>, <span class="string">&quot;Critical Value(10%)&quot;</span></span><br><span class="line">        ], columns=[<span class="string">&#x27;销量&#x27;</span>]</span><br><span class="line">    );</span><br><span class="line">    result[<span class="string">&#x27;销量&#x27;</span>][<span class="string">&#x27;Test Statistic Value&#x27;</span>] = t[<span class="number">0</span>]</span><br><span class="line">    result[<span class="string">&#x27;销量&#x27;</span>][<span class="string">&#x27;p-value&#x27;</span>] = t[<span class="number">1</span>]</span><br><span class="line">    result[<span class="string">&#x27;销量&#x27;</span>][<span class="string">&#x27;Lags Used&#x27;</span>] = t[<span class="number">2</span>]</span><br><span class="line">    result[<span class="string">&#x27;销量&#x27;</span>][<span class="string">&#x27;Number of Observations Used&#x27;</span>] = t[<span class="number">3</span>]</span><br><span class="line">    result[<span class="string">&#x27;销量&#x27;</span>][<span class="string">&#x27;Critical Value(1%)&#x27;</span>] = t[<span class="number">4</span>][<span class="string">&#x27;1%&#x27;</span>]</span><br><span class="line">    result[<span class="string">&#x27;销量&#x27;</span>][<span class="string">&#x27;Critical Value(5%)&#x27;</span>] = t[<span class="number">4</span>][<span class="string">&#x27;5%&#x27;</span>]</span><br><span class="line">    result[<span class="string">&#x27;销量&#x27;</span>][<span class="string">&#x27;Critical Value(10%)&#x27;</span>] = t[<span class="number">4</span>][<span class="string">&#x27;10%&#x27;</span>]</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;原始序列的ADF检验结果为:&#x27;</span>,tagADF(ADF(data[<span class="string">u&#x27;销量&#x27;</span>])))  <span class="comment"># 添加标签后展现</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 平稳判断：得到统计量大于三个置信度(1%,5%,10%)临界统计值，p值显著大于0.05，该序列为非平稳序列。</span></span><br><span class="line"><span class="comment"># 备注：得到的统计量显著小于3个置信度（1%，5%，10%）的临界统计值时，为平稳 此时p值接近于0 此处不为0，尝试增加数据量，原数据太少</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 2 进行数据差分，一般一阶差分就可以</span></span><br><span class="line">D_data = data.diff(<span class="number">1</span>).dropna()</span><br><span class="line">D_data.columns = [<span class="string">u&#x27;销量差分&#x27;</span>]</span><br><span class="line"> </span><br><span class="line"><span class="comment">#差分图趋势查看</span></span><br><span class="line">D_data.plot() </span><br><span class="line">plt.show()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 附加：查看自相关系数合片自相关系数（查分之后），可以用于平稳性的检测，也可用于定阶系数预估</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">#自相关图 </span></span><br><span class="line">plot_acf(D_data).show() </span><br><span class="line">plt.show()</span><br><span class="line"> </span><br><span class="line"><span class="comment">#偏自相关图</span></span><br><span class="line"><span class="keyword">from</span> statsmodels.graphics.tsaplots <span class="keyword">import</span> plot_pacf</span><br><span class="line"> </span><br><span class="line">plot_pacf(D_data).show()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 3 平稳性检测 </span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">u&#x27;差分序列的ADF检验结果为：&#x27;</span>, tagADF(ADF(D_data[<span class="string">u&#x27;销量差分&#x27;</span>]))) </span><br><span class="line"> </span><br><span class="line"><span class="comment"># 解释：Test Statistic Value值小于两个水平值，p值显著小于0.05，一阶差分后序列为平稳序列。</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 4 白噪声检验</span></span><br><span class="line"><span class="keyword">from</span> statsmodels.stats.diagnostic <span class="keyword">import</span> acorr_ljungbox</span><br><span class="line"> </span><br><span class="line"><span class="comment">#返回统计量和p值 </span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">u&#x27;差分序列的白噪声检验结果为：&#x27;</span>, acorr_ljungbox(D_data, lags=<span class="number">1</span>))  <span class="comment"># 分别为stat值（统计量）和P值</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># P值小于0.05，所以一阶差分后的序列为平稳非白噪声序列。</span></span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="comment"># 5 p，q定阶</span></span><br><span class="line"><span class="keyword">from</span> statsmodels.tsa.arima_model <span class="keyword">import</span> ARIMA</span><br><span class="line"> </span><br><span class="line"><span class="comment">#一般阶数不超过length/10 </span></span><br><span class="line">pmax = <span class="built_in">int</span>(<span class="built_in">len</span>(D_data)/<span class="number">10</span>) </span><br><span class="line">  </span><br><span class="line"><span class="comment">#一般阶数不超过length/10 </span></span><br><span class="line">qmax = <span class="built_in">int</span>(<span class="built_in">len</span>(D_data)/<span class="number">10</span>) </span><br><span class="line"> </span><br><span class="line"><span class="comment">#bic矩阵 </span></span><br><span class="line">bic_matrix = [] </span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> <span class="built_in">range</span>(pmax+<span class="number">1</span>):</span><br><span class="line">  tmp = []</span><br><span class="line">  <span class="keyword">for</span> q <span class="keyword">in</span> <span class="built_in">range</span>(qmax+<span class="number">1</span>):</span><br><span class="line">        </span><br><span class="line"><span class="comment">#存在部分报错，所以用try来跳过报错。</span></span><br><span class="line">    <span class="keyword">try</span>: </span><br><span class="line">      tmp.append(ARIMA(data, (p,<span class="number">1</span>,q)).fit().bic)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">      tmp.append(<span class="literal">None</span>)</span><br><span class="line">  bic_matrix.append(tmp)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#从中可以找出最小值 </span></span><br><span class="line">bic_matrix = pandas.DataFrame(bic_matrix) </span><br><span class="line"> </span><br><span class="line"><span class="comment">#先用stack展平，然后用idxmin找出最小值位置。 </span></span><br><span class="line">p,q = bic_matrix.stack().idxmin()  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">u&#x27;BIC最小的p值和q值为：%s、%s&#x27;</span> %(p,q))</span><br><span class="line"><span class="comment"># 取BIC信息量达到最小的模型阶数，结果p为0，q为1，定阶完成。</span></span><br><span class="line"><span class="comment"># 6 建立模型和预测</span></span><br><span class="line">model = ARIMA(data, (p,<span class="number">1</span>,q)).fit()</span><br><span class="line"></span><br><span class="line"><span class="comment">#给出一份模型报告</span></span><br><span class="line">model.summary2()</span><br><span class="line"></span><br><span class="line"><span class="comment">#作为期5天的预测，返回预测结果、标准误差、置信区间。</span></span><br><span class="line">model.forecast(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<h1 id="BP神经网络模型"><a href="#BP神经网络模型" class="headerlink" title="BP神经网络模型"></a>BP神经网络模型</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Created on Mon Oct  1 22:15:54 2018</span></span><br><span class="line"><span class="string">@author: Heisenberg</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"> </span><br><span class="line"><span class="comment">#random.seed(0)  #当我们设置相同的seed，每次生成的随机数相同。如果不设置seed，则每次会生成不同的随机数</span></span><br><span class="line">                <span class="comment">#参考https://blog.csdn.net/jiangjiang_jian/article/details/79031788</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">#生成区间[a,b]内的随机数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">random_number</span>(<span class="params">a,b</span>):</span><br><span class="line">    <span class="keyword">return</span> (b-a)*random.random()+a</span><br><span class="line"> </span><br><span class="line"><span class="comment">#生成一个矩阵，大小为m*n,并且设置默认零矩阵</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">makematrix</span>(<span class="params">m, n, fill=<span class="number">0.0</span></span>):</span><br><span class="line">    a = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">        a.append([fill]*n)</span><br><span class="line">    <span class="keyword">return</span> a</span><br><span class="line"> </span><br><span class="line"><span class="comment">#函数sigmoid(),这里采用tanh，因为看起来要比标准的sigmoid函数好看</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> math.tanh(x)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#函数sigmoid的派生函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">derived_sigmoid</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.0</span> - x**<span class="number">2</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">#构造三层BP网络架构</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BPNN</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_in, num_hidden, num_out</span>):</span><br><span class="line">        <span class="comment">#输入层，隐藏层，输出层的节点数</span></span><br><span class="line">        self.num_in = num_in + <span class="number">1</span>  <span class="comment">#增加一个偏置结点</span></span><br><span class="line">        self.num_hidden = num_hidden + <span class="number">1</span>   <span class="comment">#增加一个偏置结点</span></span><br><span class="line">        self.num_out = num_out</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#激活神经网络的所有节点（向量）</span></span><br><span class="line">        self.active_in = [<span class="number">1.0</span>]*self.num_in</span><br><span class="line">        self.active_hidden = [<span class="number">1.0</span>]*self.num_hidden</span><br><span class="line">        self.active_out = [<span class="number">1.0</span>]*self.num_out</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#创建权重矩阵</span></span><br><span class="line">        self.wight_in = makematrix(self.num_in, self.num_hidden)</span><br><span class="line">        self.wight_out = makematrix(self.num_hidden, self.num_out)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#对权值矩阵赋初值</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_in):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(self.num_hidden):</span><br><span class="line">                self.wight_in[i][j] = random_number(-<span class="number">0.2</span>, <span class="number">0.2</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_hidden):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(self.num_out):</span><br><span class="line">                self.wight_out[i][j] = random_number(-<span class="number">0.2</span>, <span class="number">0.2</span>)</span><br><span class="line">    </span><br><span class="line">        <span class="comment">#最后建立动量因子（矩阵）</span></span><br><span class="line">        self.ci = makematrix(self.num_in, self.num_hidden)</span><br><span class="line">        self.co = makematrix(self.num_hidden, self.num_out)        </span><br><span class="line">        </span><br><span class="line">    <span class="comment">#信号正向传播</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, inputs</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(inputs) != self.num_in-<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&#x27;与输入层节点数不符&#x27;</span>)</span><br><span class="line">            </span><br><span class="line">        <span class="comment">#数据输入输入层</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_in - <span class="number">1</span>):</span><br><span class="line">            <span class="comment">#self.active_in[i] = sigmoid(inputs[i])  #或者先在输入层进行数据处理</span></span><br><span class="line">            self.active_in[i] = inputs[i]  <span class="comment">#active_in[]是输入数据的矩阵</span></span><br><span class="line">            </span><br><span class="line">        <span class="comment">#数据在隐藏层的处理</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_hidden - <span class="number">1</span>):</span><br><span class="line">            <span class="built_in">sum</span> = <span class="number">0.0</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(self.num_in):</span><br><span class="line">                <span class="built_in">sum</span> = <span class="built_in">sum</span> + self.active_in[i] * self.wight_in[j][i]</span><br><span class="line">            self.active_hidden[i] = sigmoid(<span class="built_in">sum</span>)   <span class="comment">#active_hidden[]是处理完输入数据之后存储，作为输出层的输入数据</span></span><br><span class="line">            </span><br><span class="line">        <span class="comment">#数据在输出层的处理</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_out):</span><br><span class="line">            <span class="built_in">sum</span> = <span class="number">0.0</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(self.num_hidden):</span><br><span class="line">                <span class="built_in">sum</span> = <span class="built_in">sum</span> + self.active_hidden[j]*self.wight_out[j][i]</span><br><span class="line">            self.active_out[i] = sigmoid(<span class="built_in">sum</span>)   <span class="comment">#与上同理</span></span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> self.active_out[:]</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#误差反向传播</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">errorbackpropagate</span>(<span class="params">self, targets, lr, m</span>):   <span class="comment">#lr是学习率， m是动量因子</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(targets) != self.num_out:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&#x27;与输出层节点数不符！&#x27;</span>)</span><br><span class="line">            </span><br><span class="line">        <span class="comment">#首先计算输出层的误差</span></span><br><span class="line">        out_deltas = [<span class="number">0.0</span>]*self.num_out</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_out):</span><br><span class="line">            error = targets[i] - self.active_out[i]</span><br><span class="line">            out_deltas[i] = derived_sigmoid(self.active_out[i])*error</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#然后计算隐藏层误差</span></span><br><span class="line">        hidden_deltas = [<span class="number">0.0</span>]*self.num_hidden</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_hidden):</span><br><span class="line">            error = <span class="number">0.0</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(self.num_out):</span><br><span class="line">                error = error + out_deltas[j]* self.wight_out[i][j]</span><br><span class="line">            hidden_deltas[i] = derived_sigmoid(self.active_hidden[i])*error</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#首先更新输出层权值</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_hidden):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(self.num_out):</span><br><span class="line">                change = out_deltas[j]*self.active_hidden[i]</span><br><span class="line">                self.wight_out[i][j] = self.wight_out[i][j] + lr*change + m*self.co[i][j]</span><br><span class="line">                self.co[i][j] = change</span><br><span class="line">                </span><br><span class="line">        <span class="comment">#然后更新输入层权值</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_in):</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_hidden):</span><br><span class="line">                change = hidden_deltas[j]*self.active_in[i]</span><br><span class="line">                self.wight_in[i][j] = self.wight_in[i][j] + lr*change + m* self.ci[i][j]</span><br><span class="line">                self.ci[i][j] = change</span><br><span class="line">                </span><br><span class="line">        <span class="comment">#计算总误差</span></span><br><span class="line">        error = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(targets)):</span><br><span class="line">            error = error + <span class="number">0.5</span>*(targets[i] - self.active_out[i])**<span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> error</span><br><span class="line"> </span><br><span class="line">    <span class="comment">#测试</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">self, patterns</span>):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> patterns:</span><br><span class="line">            <span class="built_in">print</span>(i[<span class="number">0</span>], <span class="string">&#x27;-&gt;&#x27;</span>, self.update(i[<span class="number">0</span>]))</span><br><span class="line">    <span class="comment">#权重</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">weights</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;输入层权重&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_in):</span><br><span class="line">            <span class="built_in">print</span>(self.wight_in[i])</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;输出层权重&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_hidden):</span><br><span class="line">            <span class="built_in">print</span>(self.wight_out[i])</span><br><span class="line">            </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, pattern, itera=<span class="number">100000</span>, lr = <span class="number">0.1</span>, m=<span class="number">0.1</span></span>):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(itera):</span><br><span class="line">            error = <span class="number">0.0</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> pattern:</span><br><span class="line">                inputs = j[<span class="number">0</span>]</span><br><span class="line">                targets = j[<span class="number">1</span>]</span><br><span class="line">                self.update(inputs)</span><br><span class="line">                error = error + self.errorbackpropagate(targets, lr, m)</span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;误差 %-.5f&#x27;</span> % error)</span><br><span class="line">    </span><br><span class="line"><span class="comment">#实例</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">demo</span>():</span><br><span class="line">    patt = [</span><br><span class="line">            [[<span class="number">1</span>,<span class="number">2</span>,<span class="number">5</span>],[<span class="number">0</span>]],</span><br><span class="line">            [[<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">1</span>]],</span><br><span class="line">            [[<span class="number">1</span>,<span class="number">6</span>,<span class="number">2</span>],[<span class="number">1</span>]],</span><br><span class="line">            [[<span class="number">1</span>,<span class="number">5</span>,<span class="number">1</span>],[<span class="number">0</span>]],</span><br><span class="line">            [[<span class="number">1</span>,<span class="number">8</span>,<span class="number">4</span>],[<span class="number">1</span>]]</span><br><span class="line">            ]</span><br><span class="line">    <span class="comment">#创建神经网络，3个输入节点，3个隐藏层节点，1个输出层节点</span></span><br><span class="line">    n = BPNN(<span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="comment">#训练神经网络</span></span><br><span class="line">    n.train(patt)</span><br><span class="line">    <span class="comment">#测试神经网络</span></span><br><span class="line">    n.test(patt)</span><br><span class="line">    <span class="comment">#查阅权重值</span></span><br><span class="line">    n.weights()</span><br><span class="line"> </span><br><span class="line">     </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    demo()</span><br></pre></td></tr></table></figure>

<h1 id="拟合模型"><a href="#拟合模型" class="headerlink" title="拟合模型"></a>拟合模型</h1><p>拟合数据<br>       x &#x3D; np.arange(1, 31, 1)<br>       y &#x3D; np.array([20, 23, 26, 29, 32, 35, 38, 45, 53, 62, 73, 86, 101, 118,           138, 161, 188, 220, 257, 300, 350, 409, 478, 558, 651, 760, 887, 1035, 1208, 1410])</p>
<h2 id="多项式拟合"><a href="#多项式拟合" class="headerlink" title="多项式拟合"></a>多项式拟合</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 由泰勒公式知道：任何一个函数都可以拆分成近似于这个函数的多项式表达。</span></span><br><span class="line">多项式拟合需要用到的函数是np.polyfit，它的使用方法为：</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">polyfit</span>(<span class="params">x, y, deg, rcond=<span class="literal">None</span>, full=<span class="literal">False</span>, w=<span class="literal">None</span>, cov=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Least squares polynomial fit.</span></span><br><span class="line"><span class="string">    Fit a polynomial ``p(x) = p[0] * x**deg + ... + p[deg]`` of degree `deg`</span></span><br><span class="line"><span class="string">    to points `(x, y)`. Returns a vector of coefficients `p` that minimises</span></span><br><span class="line"><span class="string">    the squared error.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 其中需要关注的参数为3个：x、y分别为需要拟合的散点的坐标序列，deg为需要拟合的多项式的最高项数。</span></span><br><span class="line">例如：</span><br><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"><span class="keyword">import</span> pylab</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">  x = np.arange(<span class="number">1</span>, <span class="number">31</span>, <span class="number">1</span>)</span><br><span class="line">  y = np.array([<span class="number">20</span>, <span class="number">23</span>, <span class="number">26</span>, <span class="number">29</span>, <span class="number">32</span>, <span class="number">35</span>, <span class="number">38</span>, <span class="number">45</span>, <span class="number">53</span>, <span class="number">62</span>, <span class="number">73</span>, <span class="number">86</span>, <span class="number">101</span>, <span class="number">118</span>, <span class="number">138</span>, <span class="number">161</span>, <span class="number">188</span>, <span class="number">220</span>, <span class="number">257</span>, <span class="number">300</span>, <span class="number">350</span>, <span class="number">409</span>, <span class="number">478</span>, <span class="number">558</span>, <span class="number">651</span>, <span class="number">760</span>, <span class="number">887</span>, <span class="number">1035</span>, <span class="number">1208</span>, <span class="number">1410</span>])</span><br><span class="line"></span><br><span class="line">  z1 = np.polyfit(x, y, <span class="number">3</span>)              <span class="comment"># 曲线拟合，返回值为多项式的各项系数</span></span><br><span class="line">  p1 = np.poly1d(z1)                    <span class="comment"># 返回值为多项式的表达式，也就是函数式子</span></span><br><span class="line">  <span class="built_in">print</span>(p1)</span><br><span class="line">  y_pred = p1(x)                        <span class="comment"># 根据函数的多项式表达式，求解 y</span></span><br><span class="line">  <span class="comment"># print(np.polyval(p1, 29))             根据多项式求解特定 x 对应的 y 值</span></span><br><span class="line">  <span class="comment"># print(np.polyval(z1, 29))             根据多项式求解特定 x 对应的 y 值</span></span><br><span class="line"></span><br><span class="line">  plot1 = pylab.plot(x, y, <span class="string">&#x27;*&#x27;</span>, label=<span class="string">&#x27;original values&#x27;</span>)</span><br><span class="line">  plot2 = pylab.plot(x, y_pred, <span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;fit values&#x27;</span>)</span><br><span class="line">  pylab.title(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">  pylab.xlabel(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">  pylab.ylabel(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">  pylab.legend(loc=<span class="number">3</span>, borderaxespad=<span class="number">0.</span>, bbox_to_anchor=(<span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line">  pylab.show()</span><br><span class="line">  pylab.savefig(<span class="string">&#x27;p1.png&#x27;</span>, dpi=<span class="number">200</span>, bbox_inches=<span class="string">&#x27;tight&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="非多项式拟合"><a href="#非多项式拟合" class="headerlink" title="非多项式拟合"></a>非多项式拟合</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果需要进行多项式拟合，你必须大体上知道散点的大致曲线形式，大致的函数的形式。</span></span><br><span class="line">比如，例子中的散点看起来像是指数的函数分布，因此可以给出func的函数：</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">func</span>(<span class="params">x, a, b, c</span>):</span><br><span class="line">  <span class="keyword">return</span> b * np.power(a, x) + c</span><br><span class="line"></span><br><span class="line"><span class="comment"># 只要给出具体的函数形式(可以是任意的，只要能写的出来皆可)，用最小二乘的方式去逼近和拟合，即求出函数的各项系数。</span></span><br><span class="line"><span class="comment"># 此时用到的是scipy.optimize包下的curve_fit函数了：</span></span><br><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"><span class="keyword">import</span> pylab</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sys, os</span><br><span class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> curve_fit</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">func</span>(<span class="params">x, a, b, c</span>):</span><br><span class="line">  <span class="keyword">return</span> b * np.power(a, x) + c</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">  x = np.arange(<span class="number">1</span>, <span class="number">31</span>, <span class="number">1</span>)</span><br><span class="line">  y = np.array([<span class="number">20</span>, <span class="number">23</span>, <span class="number">26</span>, <span class="number">29</span>, <span class="number">32</span>, <span class="number">35</span>, <span class="number">38</span>, <span class="number">45</span>, <span class="number">53</span>, <span class="number">62</span>, <span class="number">73</span>, <span class="number">86</span>, <span class="number">101</span>, <span class="number">118</span>, <span class="number">138</span>, <span class="number">161</span>, <span class="number">188</span>, <span class="number">220</span>, <span class="number">257</span>, <span class="number">300</span>, <span class="number">350</span>, <span class="number">409</span>, <span class="number">478</span>, <span class="number">558</span>, <span class="number">651</span>, <span class="number">760</span>, <span class="number">887</span>, <span class="number">1035</span>, <span class="number">1208</span>, <span class="number">1410</span>])</span><br><span class="line"></span><br><span class="line">  popt, pcov = curve_fit(func, x, y)                <span class="comment"># 曲线拟合，popt为函数的参数list</span></span><br><span class="line">  y_pred = [func(i, popt[<span class="number">0</span>], popt[<span class="number">1</span>], popt[<span class="number">2</span>]) <span class="keyword">for</span> i <span class="keyword">in</span> x]    <span class="comment"># 直接用函数和函数参数list来进行y值的计算</span></span><br><span class="line">  <span class="built_in">print</span>(popt)</span><br><span class="line"></span><br><span class="line">  plot1 = pylab.plot(x, y, <span class="string">&#x27;*&#x27;</span>, label=<span class="string">&#x27;original values&#x27;</span>)</span><br><span class="line">  plot2 = pylab.plot(x, y_pred, <span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;fit values&#x27;</span>)</span><br><span class="line">  pylab.title(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">  pylab.xlabel(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">  pylab.ylabel(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">  pylab.legend(loc=<span class="number">3</span>, borderaxespad=<span class="number">0.</span>, bbox_to_anchor=(<span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line">  pylab.show()</span><br><span class="line">  pylab.savefig(<span class="string">&#x27;p1.png&#x27;</span>, dpi=<span class="number">200</span>, bbox_inches=<span class="string">&#x27;tight&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="智能优化之粒子群模型"><a href="#智能优化之粒子群模型" class="headerlink" title="智能优化之粒子群模型"></a>智能优化之粒子群模型</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fit_fun</span>(<span class="params">x</span>):  <span class="comment"># 适应函数</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span>(<span class="number">100.0</span> * (x[<span class="number">0</span>][<span class="number">1</span>:] - x[<span class="number">0</span>][:-<span class="number">1</span>] ** <span class="number">2.0</span>) ** <span class="number">2.0</span> + (<span class="number">1</span> - x[<span class="number">0</span>][:-<span class="number">1</span>]) ** <span class="number">2.0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Particle</span>:</span><br><span class="line">    <span class="comment"># 初始化</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, x_max, max_vel, dim</span>):</span><br><span class="line">        self.__pos = np.random.uniform(-x_max, x_max, (<span class="number">1</span>, dim))  <span class="comment"># 粒子的位置</span></span><br><span class="line">        self.__vel = np.random.uniform(-max_vel, max_vel, (<span class="number">1</span>, dim))  <span class="comment"># 粒子的速度</span></span><br><span class="line">        self.__bestPos = np.zeros((<span class="number">1</span>, dim))  <span class="comment"># 粒子最好的位置</span></span><br><span class="line">        self.__fitnessValue = fit_fun(self.__pos)  <span class="comment"># 适应度函数值</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">set_pos</span>(<span class="params">self, value</span>):</span><br><span class="line">        self.__pos = value</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_pos</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.__pos</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">set_best_pos</span>(<span class="params">self, value</span>):</span><br><span class="line">        self.__bestPos = value</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_best_pos</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.__bestPos</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">set_vel</span>(<span class="params">self, value</span>):</span><br><span class="line">        self.__vel = value</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_vel</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.__vel</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">set_fitness_value</span>(<span class="params">self, value</span>):</span><br><span class="line">        self.__fitnessValue = value</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_fitness_value</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.__fitnessValue</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PSO</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, size, iter_num, x_max, max_vel, tol, best_fitness_value=<span class="built_in">float</span>(<span class="params"><span class="string">&#x27;Inf&#x27;</span></span>), C1=<span class="number">2</span>, C2=<span class="number">2</span>, W=<span class="number">1</span></span>):</span><br><span class="line">        self.C1 = C1</span><br><span class="line">        self.C2 = C2</span><br><span class="line">        self.W = W</span><br><span class="line">        self.dim = dim  <span class="comment"># 粒子的维度</span></span><br><span class="line">        self.size = size  <span class="comment"># 粒子个数</span></span><br><span class="line">        self.iter_num = iter_num  <span class="comment"># 迭代次数</span></span><br><span class="line">        self.x_max = x_max</span><br><span class="line">        self.max_vel = max_vel  <span class="comment"># 粒子最大速度</span></span><br><span class="line">        self.tol = tol  <span class="comment"># 截至条件</span></span><br><span class="line">        self.best_fitness_value = best_fitness_value</span><br><span class="line">        self.best_position = np.zeros((<span class="number">1</span>, dim))  <span class="comment"># 种群最优位置</span></span><br><span class="line">        self.fitness_val_list = []  <span class="comment"># 每次迭代最优适应值</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 对种群进行初始化</span></span><br><span class="line">        self.Particle_list = [Particle(self.x_max, self.max_vel, self.dim) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.size)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">set_bestFitnessValue</span>(<span class="params">self, value</span>):</span><br><span class="line">        self.best_fitness_value = value</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_bestFitnessValue</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.best_fitness_value</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">set_bestPosition</span>(<span class="params">self, value</span>):</span><br><span class="line">        self.best_position = value</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_bestPosition</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.best_position</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 更新速度</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update_vel</span>(<span class="params">self, part</span>):</span><br><span class="line">        vel_value = self.W * part.get_vel() + self.C1 * np.random.rand() * (part.get_best_pos() - part.get_pos()) \</span><br><span class="line">                    + self.C2 * np.random.rand() * (self.get_bestPosition() - part.get_pos())</span><br><span class="line">        vel_value[vel_value &gt; self.max_vel] = self.max_vel</span><br><span class="line">        vel_value[vel_value &lt; -self.max_vel] = -self.max_vel</span><br><span class="line">        part.set_vel(vel_value)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 更新位置</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update_pos</span>(<span class="params">self, part</span>):</span><br><span class="line">        pos_value = part.get_pos() + part.get_vel()</span><br><span class="line">        part.set_pos(pos_value)</span><br><span class="line">        value = fit_fun(part.get_pos())</span><br><span class="line">        <span class="keyword">if</span> value &lt; part.get_fitness_value():</span><br><span class="line">            part.set_fitness_value(value)</span><br><span class="line">            part.set_best_pos(pos_value)</span><br><span class="line">        <span class="keyword">if</span> value &lt; self.get_bestFitnessValue():</span><br><span class="line">            self.set_bestFitnessValue(value)</span><br><span class="line">            self.set_bestPosition(pos_value)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update_ndim</span>(<span class="params">self</span>):</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.iter_num):</span><br><span class="line">            <span class="keyword">for</span> part <span class="keyword">in</span> self.Particle_list:</span><br><span class="line">                self.update_vel(part)  <span class="comment"># 更新速度</span></span><br><span class="line">                self.update_pos(part)  <span class="comment"># 更新位置</span></span><br><span class="line">            self.fitness_val_list.append(self.get_bestFitnessValue())  <span class="comment"># 每次迭代完把当前的最优适应度存到列表</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;第&#123;&#125;次最佳适应值为&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(i, self.get_bestFitnessValue()))</span><br><span class="line">            <span class="keyword">if</span> self.get_bestFitnessValue() &lt; self.tol:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self.fitness_val_list, self.get_bestPosition()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># test 香蕉函数</span></span><br><span class="line">    pso = PSO(<span class="number">4</span>, <span class="number">5</span>, <span class="number">10000</span>, <span class="number">30</span>, <span class="number">60</span>, <span class="number">1e-4</span>, C1=<span class="number">2</span>, C2=<span class="number">2</span>, W=<span class="number">1</span>)</span><br><span class="line">    fit_var_list, best_pos = pso.update_ndim()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;最优位置:&quot;</span> + <span class="built_in">str</span>(best_pos))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;最优解:&quot;</span> + <span class="built_in">str</span>(fit_var_list[-<span class="number">1</span>]))</span><br><span class="line">    plt.plot(<span class="built_in">range</span>(<span class="built_in">len</span>(fit_var_list)), fit_var_list, alpha=<span class="number">0.5</span>)</span><br></pre></td></tr></table></figure>

<h1 id="主成分分析算法"><a href="#主成分分析算法" class="headerlink" title="主成分分析算法"></a>主成分分析算法</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt                 <span class="comment">#加载matplotlib用于数据的可视化</span></span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA           <span class="comment">#加载PCA算法包</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"> </span><br><span class="line">data=load_iris()</span><br><span class="line">y=data.target</span><br><span class="line">x=data.data</span><br><span class="line">pca=PCA(n_components=<span class="number">2</span>)     <span class="comment">#加载PCA算法，设置降维后主成分数目为2</span></span><br><span class="line">reduced_x=pca.fit_transform(x)<span class="comment">#对样本进行降维</span></span><br><span class="line">red_x,red_y=[],[]</span><br><span class="line">blue_x,blue_y=[],[]</span><br><span class="line">green_x,green_y=[],[]</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(reduced_x)):</span><br><span class="line">    <span class="keyword">if</span> y[i] ==<span class="number">0</span>:</span><br><span class="line">        red_x.append(reduced_x[i][<span class="number">0</span>])</span><br><span class="line">        red_y.append(reduced_x[i][<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">elif</span> y[i]==<span class="number">1</span>:</span><br><span class="line">        blue_x.append(reduced_x[i][<span class="number">0</span>])</span><br><span class="line">        blue_y.append(reduced_x[i][<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        green_x.append(reduced_x[i][<span class="number">0</span>])</span><br><span class="line">        green_y.append(reduced_x[i][<span class="number">1</span>])</span><br><span class="line"><span class="comment">#可视化</span></span><br><span class="line">plt.scatter(red_x,red_y,c=<span class="string">&#x27;r&#x27;</span>,marker=<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.scatter(blue_x,blue_y,c=<span class="string">&#x27;b&#x27;</span>,marker=<span class="string">&#x27;D&#x27;</span>)</span><br><span class="line">plt.scatter(green_x,green_y,c=<span class="string">&#x27;g&#x27;</span>,marker=<span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h1 id="卷积神经网络模型"><a href="#卷积神经网络模型" class="headerlink" title="卷积神经网络模型"></a>卷积神经网络模型</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#卷积神经网络手写字体识别代码</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"> </span><br><span class="line"><span class="comment">#初始化权重函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">weight_variable</span>(<span class="params">shape</span>):</span><br><span class="line">    initial = tf.truncated_normal(shape,stddev=<span class="number">0.1</span>);<span class="comment">#生成维度是shape标准差是0.1的正态分布数</span></span><br><span class="line">    <span class="keyword">return</span> tf.Variable(initial)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#初始化偏置项</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">bias_variable</span>(<span class="params">shape</span>):</span><br><span class="line">    initial = tf.constant(<span class="number">0.1</span>,shape=shape)<span class="comment">#生成维度为shape的全为0.1的向量</span></span><br><span class="line">    <span class="keyword">return</span> tf.Variable(initial)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#定义卷积函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">conv2d</span>(<span class="params">x,w</span>):</span><br><span class="line">    <span class="keyword">return</span> tf.nn.conv2d(x,w,strides=[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],padding=<span class="string">&#x27;SAME&#x27;</span>)</span><br><span class="line">    <span class="comment">#strides： 卷积时在图像每一维的步长，这是一个一维的向量，</span></span><br><span class="line">    <span class="comment">#[ 1, strides, strides, 1]，第一位和最后一位固定必须是1</span></span><br><span class="line">    <span class="comment">#padding参数是string类型，值为“SAME” 和 “VALID”，表示的是卷积的形式。</span></span><br><span class="line">    <span class="comment">#设置为&quot;SAME&quot;时，会在原图像边缘外增加几圈0来使卷积后的矩阵和原图像矩阵的维度相同</span></span><br><span class="line">    <span class="comment">#设置为&quot;VALID&quot;则不考虑这一点，卷积后的矩阵维度会相应减少，例如原图像如果是5*5，卷积核是3*3</span></span><br><span class="line">    <span class="comment">#那么卷积过后的输出矩阵回是3*3的</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">#定义一个2*2的最大池化层</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">max_pool_2_2</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> tf.nn.max_pool(x,ksize=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],strides=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],padding=<span class="string">&#x27;SAME&#x27;</span>)</span><br><span class="line">    <span class="comment">#第一个参数value：需要池化的输入，一般池化层接在卷积层后面，</span></span><br><span class="line">    <span class="comment">#依然是[batch, height, width, channels]这样的shape</span></span><br><span class="line">    <span class="comment">#第二个参数ksize：池化窗口的大小，取一个四维向量，一般是[1, height, width, 1]，</span></span><br><span class="line">    <span class="comment">#因为我们不想在batch和channels上做池化，所以这两个维度设为了1</span></span><br><span class="line">    <span class="comment">#第三个参数strides：和卷积类似，窗口在每一个维度上滑动的步长，</span></span><br><span class="line">    <span class="comment">#一般也是[1, stride,stride, 1]</span></span><br><span class="line">    <span class="comment">#第四个参数padding：和卷积类似，可以取&#x27;VALID&#x27; 或者&#x27;SAME&#x27;</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment">#定义输入变量</span></span><br><span class="line">    x = tf.placeholder(<span class="string">&quot;float&quot;</span>,shape=[<span class="literal">None</span>,<span class="number">784</span>])<span class="comment">#占位    </span></span><br><span class="line">    <span class="comment">#浮点型变量，行数不定，列数为784(每个图像是一个长度为784（28*28）的向量)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#定义输出变量</span></span><br><span class="line">    y_ = tf.placeholder(<span class="string">&quot;float&quot;</span>,shape=[<span class="literal">None</span>,<span class="number">10</span>])<span class="comment">#占位</span></span><br><span class="line">    <span class="comment">#浮点型变量，行数不定，列数为10,输出一个长度为10的向量来表示每个数字的可能性</span></span><br><span class="line">    <span class="comment">#初始化权重,第一层卷积，32的意思代表的是输出32个通道</span></span><br><span class="line">    <span class="comment"># 其实，也就是设置32个卷积，每一个卷积都会对图像进行卷积操作</span></span><br><span class="line">    </span><br><span class="line">    w_conv1 = weight_variable([<span class="number">5</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">32</span>])<span class="comment">###生成了32个5*5的矩阵</span></span><br><span class="line">    <span class="comment">#初始化偏置项</span></span><br><span class="line">    b_conv1 = bias_variable([<span class="number">32</span>])</span><br><span class="line">    </span><br><span class="line">    x_image = tf.reshape(x,[-<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>])</span><br><span class="line">    <span class="comment">#将输入的x转成一个4D向量，第2、3维对应图片的宽高，最后一维代表图片的颜色通道数</span></span><br><span class="line">    <span class="comment"># 输入的图像为灰度图，所以通道数为1，如果是RGB图，通道数为3</span></span><br><span class="line">    <span class="comment"># tf.reshape(x,[-1,28,28,1])的意思是将x自动转换成28*28*1的数组</span></span><br><span class="line">    <span class="comment"># -1的意思是代表不知道x的shape，它会按照后面的设置进行转换</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 卷积并激活</span></span><br><span class="line">    h_conv1 = tf.nn.relu(conv2d(x_image,w_conv1) + b_conv1)</span><br><span class="line">    <span class="comment">#池化</span></span><br><span class="line">    h_pool1 = max_pool_2_2(h_conv1)</span><br><span class="line">    <span class="comment">#第二层卷积</span></span><br><span class="line">    <span class="comment">#初始权重</span></span><br><span class="line">    w_conv2 = weight_variable([<span class="number">5</span>,<span class="number">5</span>,<span class="number">32</span>,<span class="number">64</span>])</span><br><span class="line">    <span class="comment">#在32个第一层卷积层上每个再用一个5*5的卷积核在做特征提取，并输出到第二层卷积层，</span></span><br><span class="line">    <span class="comment">#第二层设置了64个卷积层</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#初始化偏置项</span></span><br><span class="line">    b_conv2 = bias_variable([<span class="number">64</span>])</span><br><span class="line">    <span class="comment">#将第一层卷积池化后的结果作为第二层卷积的输入加权求和后激活</span></span><br><span class="line">    h_conv2 = tf.nn.relu(conv2d(h_pool1,w_conv2) + b_conv2)</span><br><span class="line">    <span class="comment">#池化</span></span><br><span class="line">    h_pool2 = max_pool_2_2(h_conv2)</span><br><span class="line">    <span class="comment"># 设置全连接层的权重</span></span><br><span class="line">    w_fc1 = weight_variable([<span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>,<span class="number">1024</span>])</span><br><span class="line">    <span class="comment">#28*28的原图像经过两次池化后变为7*7，设置了1024个输出单元</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 设置全连接层的偏置</span></span><br><span class="line">    b_fc1 = bias_variable([<span class="number">1024</span>])</span><br><span class="line">    <span class="comment"># 将第二层卷积池化后的结果，转成一个7*7*64的数组</span></span><br><span class="line">    h_pool2_flat = tf.reshape(h_pool2,[-<span class="number">1</span>,<span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>])</span><br><span class="line">    <span class="comment"># 通过全连接之后并激活</span></span><br><span class="line">    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,w_fc1) + b_fc1)</span><br><span class="line">    <span class="comment"># 防止过拟合</span></span><br><span class="line">    keep_prob = tf.placeholder(<span class="string">&quot;float&quot;</span>)<span class="comment">#占位</span></span><br><span class="line">    h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)</span><br><span class="line">    <span class="comment">#设置每个单元保留的概率来随机放弃一些单元来防止过拟合</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment">#输出层</span></span><br><span class="line">    w_fc2 = weight_variable([<span class="number">1024</span>,<span class="number">10</span>])</span><br><span class="line">    b_fc2 = bias_variable([<span class="number">10</span>])</span><br><span class="line">    <span class="comment">#加权求和并激活</span></span><br><span class="line">    y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop,w_fc2) + b_fc2)</span><br><span class="line"> </span><br><span class="line">    <span class="comment">#日志输出，每迭代100次输出一次日志</span></span><br><span class="line">    <span class="comment">#定义交叉熵为损失函数</span></span><br><span class="line">    cross_entropy = -tf.reduce_sum(y_ * tf.log(y_conv))</span><br><span class="line">    <span class="comment">#最小化交叉熵</span></span><br><span class="line">    train_step = tf.train.AdamOptimizer(<span class="number">1e-4</span>).minimize(cross_entropy)</span><br><span class="line">    <span class="comment">#计算准确率</span></span><br><span class="line">    correct_prediction = tf.equal(tf.argmax(y_conv,<span class="number">1</span>),tf.argmax(y_,<span class="number">1</span>))</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct_prediction,<span class="string">&quot;float&quot;</span>))</span><br><span class="line">    sess = tf.Session()</span><br><span class="line">    sess.run(tf.initialize_all_variables())</span><br><span class="line">    <span class="comment">#上面的两行是在为tf的输出变量做准备</span></span><br><span class="line">    <span class="comment"># 下载minist的手写数字的数据集</span></span><br><span class="line">    mnist = input_data.read_data_sets(<span class="string">&quot;MNIST_data/&quot;</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20000</span>):<span class="comment">#迭代20000次</span></span><br><span class="line">        batch = mnist.train.next_batch(<span class="number">50</span>)<span class="comment">#设置batch，即每次用来训练模型的数据个数</span></span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:<span class="comment">#每100次迭代输出一次精度</span></span><br><span class="line">            train_accuracy = accuracy.<span class="built_in">eval</span>(session=sess,</span><br><span class="line">                                           feed_dict=&#123;x:batch[<span class="number">0</span>],y_:batch[<span class="number">1</span>],keep_prob:<span class="number">1.0</span>&#125;)</span><br><span class="line">            <span class="comment">#喂给之前占位的x和y_本次训练的batch个数据中第一个数据的图像矩阵和标签，不考虑过拟合</span></span><br><span class="line">            <span class="comment">#计算当前的精度</span></span><br><span class="line">            </span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;step %d,training accuracy %g&quot;</span>%(i,train_accuracy))</span><br><span class="line">        train_step.run(session = sess,feed_dict=&#123;x:batch[<span class="number">0</span>],y_:batch[<span class="number">1</span>],keep_prob:<span class="number">0.5</span>&#125;)</span><br><span class="line">        <span class="comment">#当i不能被100整除时的训练过程，考虑过拟合，单元保留的概率为0.5</span></span><br></pre></td></tr></table></figure>

<h1 id="支持向量机模型"><a href="#支持向量机模型" class="headerlink" title="支持向量机模型"></a>支持向量机模型</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">kernelTrans</span>(<span class="params">X,A,kTup</span>):                    <span class="comment"># 核函数(此例未使用)</span></span><br><span class="line">    m,n=shape(X)</span><br><span class="line">    K = mat(zeros((m,<span class="number">1</span>)))</span><br><span class="line">    <span class="keyword">if</span> kTup[<span class="number">0</span>] ==<span class="string">&#x27;lin&#x27;</span>:</span><br><span class="line">        K=X*A.T</span><br><span class="line">    <span class="keyword">elif</span> kTup[<span class="number">0</span>]==<span class="string">&#x27;rbf&#x27;</span>:</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">            deltaRow = X[j,:]-A</span><br><span class="line">            K[j]=deltaRow*deltaRow.T           <span class="comment"># ||w||^2 = w^T * w</span></span><br><span class="line">        K =exp(K/(-<span class="number">1</span>*kTup[<span class="number">1</span>]**<span class="number">2</span>))              <span class="comment"># K = e^(||x-y||^2 / (-2*sigma^2))</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> NameError(<span class="string">&quot;Houston we Have a problem --&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> K</span><br><span class="line"> </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">optStruct</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,dataMain,classLabel,C,toler,kTup</span>):</span><br><span class="line"> </span><br><span class="line">        self.X = dataMain                     <span class="comment"># 样本矩阵</span></span><br><span class="line">        self.labelMat = classLabel</span><br><span class="line">        self.C = C                            <span class="comment"># 惩罚因子</span></span><br><span class="line">        self.tol = toler                      <span class="comment"># 容错率</span></span><br><span class="line">        self.m = shape(dataMain)[<span class="number">0</span>]           <span class="comment"># 样本点个数</span></span><br><span class="line">        self.alphas = mat(zeros((self.m,<span class="number">1</span>)))  <span class="comment"># 产生m个拉格郎日乘子，组成一个m×1的矩阵</span></span><br><span class="line">        self.b =<span class="number">0</span>                             <span class="comment"># 决策面的截距</span></span><br><span class="line">        self.eCache = mat(zeros((self.m,<span class="number">2</span>)))    <span class="comment"># 产生m个误差 E=f(x)-y ,设置成m×2的矩阵，矩阵第一列是标志位，标志为1就是E计算好了，第二列是误差E</span></span><br><span class="line">        <span class="comment"># self.K = mat(zeros((self.m,self.m)))</span></span><br><span class="line">        <span class="comment"># for i in range(self.m):               # K[,]保存的是任意样本之间的相似度(用高斯核函数表示的相似度)</span></span><br><span class="line">        <span class="comment">#     self.K[:,i]=kernelTrans(self.X,self.X[i,:],kTup)</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loadDataSet</span>(<span class="params">filename</span>):                 <span class="comment"># 加载数据</span></span><br><span class="line">    dataMat = []</span><br><span class="line">    labelMat = []</span><br><span class="line">    fr = <span class="built_in">open</span>(filename)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</span><br><span class="line">        lineArr = line.split()</span><br><span class="line">        dataMat.append([<span class="built_in">float</span>(lineArr[<span class="number">0</span>]),<span class="built_in">float</span>(lineArr[<span class="number">1</span>])])</span><br><span class="line">        labelMat.append(<span class="built_in">float</span>(lineArr[<span class="number">2</span>]))     <span class="comment"># 一维列表</span></span><br><span class="line">    <span class="keyword">return</span> dataMat, labelMat</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">selectJrand</span>(<span class="params">i, m</span>):       <span class="comment"># 随机选择一个不等于i的下标</span></span><br><span class="line">    j =i</span><br><span class="line">    <span class="keyword">while</span>(j==i):</span><br><span class="line">        j = <span class="built_in">int</span>(random.uniform(<span class="number">0</span>,m))</span><br><span class="line">    <span class="keyword">return</span> j</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">clipAlpha</span>(<span class="params">aj, H,L</span>):</span><br><span class="line">    <span class="keyword">if</span> aj&gt;H:                      <span class="comment"># 如果a^new 大于上限值，那么就把上限赋给它</span></span><br><span class="line">        aj = H</span><br><span class="line">    <span class="keyword">if</span> L&gt;aj:                      <span class="comment"># 如果a^new 小于下限值，那么就把下限赋给它</span></span><br><span class="line">        aj = L</span><br><span class="line">    <span class="keyword">return</span> aj</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calcEk</span>(<span class="params">oS, k</span>):           <span class="comment"># 计算误差E, k代表第k个样本点，它是下标，oS是optStruct类的实例</span></span><br><span class="line">    <span class="comment"># fXk = float(multiply(oS.alphas,oS.labelMat).T * oS.K[:,k] + oS.b)   # 公式f(x)=sum(ai*yi*xi^T*x)+b</span></span><br><span class="line">    fXk = <span class="built_in">float</span>(multiply(oS.alphas,oS.labelMat).T * (oS.X*oS.X[k,:].T)) +oS.b</span><br><span class="line">    Ek = fXk - <span class="built_in">float</span>(oS.labelMat[k])          <span class="comment"># 计算误差 E=f(x)-y</span></span><br><span class="line">    <span class="keyword">return</span> Ek</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">selectJ</span>(<span class="params">i, oS, Ei</span>):      <span class="comment"># 选择两个拉格郎日乘子,在所有样本点的误差计算完毕之后，寻找误差变化最大的那个样本点及其误差</span></span><br><span class="line">    maxK = -<span class="number">1</span>                <span class="comment"># 最大步长的因子的下标</span></span><br><span class="line">    maxDeltaE = <span class="number">0</span>            <span class="comment"># 最大步长</span></span><br><span class="line">    Ej = <span class="number">0</span>                   <span class="comment"># 最大步长的因子的误差</span></span><br><span class="line">    oS.eCache[i] = [<span class="number">1</span>,Ei]</span><br><span class="line">    valiEcacheList = nonzero(oS.eCache[:,<span class="number">0</span>].A)[<span class="number">0</span>]    <span class="comment"># nonzero结果是两个array数组，第一个数组是不为0的元素的x坐标，第二个数组是该位置的y坐标</span></span><br><span class="line">                                                  <span class="comment"># 此处寻找误差矩阵第一列不为0的数的下标</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;valiEcacheList is &#123;&#125;&quot;</span>.<span class="built_in">format</span>(valiEcacheList))</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">len</span>(valiEcacheList))&gt;<span class="number">1</span>:</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> valiEcacheList:          <span class="comment"># 遍历所有计算好的Ei的下标，valiEcacheLIst保存了所有样本点的E，计算好的有效位置是1,没计算好的是0</span></span><br><span class="line"> </span><br><span class="line">            <span class="keyword">if</span> k == i:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            Ek = calcEk(oS,k)</span><br><span class="line">            deltaE = <span class="built_in">abs</span>(Ei-Ek)          <span class="comment"># 距离第一个拉格朗日乘子a1绝对值最远的作为第二个朗格朗日乘子a2</span></span><br><span class="line">            <span class="keyword">if</span> deltaE&gt;maxDeltaE:</span><br><span class="line">                maxK = k                 <span class="comment"># 记录选中的这个乘子a2的下标</span></span><br><span class="line">                maxDeltaE = deltaE       <span class="comment"># 记录他俩的绝对值</span></span><br><span class="line">                Ej = Ek                  <span class="comment"># 记录a2此时的误差</span></span><br><span class="line">        <span class="keyword">return</span> maxK, Ej</span><br><span class="line">    <span class="keyword">else</span>:                             <span class="comment"># 如果是第一次循环，随机选择一个alphas</span></span><br><span class="line">        j = selectJrand(i, oS.m)</span><br><span class="line">        <span class="comment"># j = 72</span></span><br><span class="line">        Ej = calcEk(oS, j)</span><br><span class="line">    <span class="keyword">return</span> j,Ej</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">updateEk</span>(<span class="params">oS, k</span>):</span><br><span class="line">    Ek = calcEk(oS, k)</span><br><span class="line">    oS.eCache[k] = [<span class="number">1</span>,Ek]        <span class="comment"># 把第k个样本点的误差计算出来，并存入误差矩阵，有效位置设为1</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">innerL</span>(<span class="params">i, oS</span>):</span><br><span class="line">    Ei = calcEk(oS, i)           <span class="comment"># KKT条件， 若yi*(w^T * x +b)-1&lt;0 则 ai=C  若yi*(w^T * x +b)-1&gt;0 则 ai=0</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;i is &#123;0&#125;,Ei is &#123;1&#125;&quot;</span>.<span class="built_in">format</span>(i,Ei))</span><br><span class="line">    <span class="keyword">if</span> ((oS.labelMat[i]*Ei &lt; -oS.tol) <span class="keyword">and</span> (oS.alphas[i] &lt; oS.C)) <span class="keyword">or</span> ((oS.labelMat[i]*Ei &gt; oS.tol) <span class="keyword">and</span> (oS.alphas[i] &gt; <span class="number">0</span>)):</span><br><span class="line">        j,Ej = selectJ(i,oS,Ei)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;第二个因子的坐标&#123;&#125;&quot;</span>.<span class="built_in">format</span>(j))</span><br><span class="line">        alphaIold = oS.alphas[i].copy()       <span class="comment"># 用了浅拷贝， alphaIold 就是old a1,对应公式</span></span><br><span class="line">        alphaJold = oS.alphas[j].copy()</span><br><span class="line">        <span class="keyword">if</span> oS.labelMat[i] != oS.labelMat[j]:  <span class="comment"># 也是根据公式来的，y1 不等于 y2时</span></span><br><span class="line">            L = <span class="built_in">max</span>(<span class="number">0</span>,oS.alphas[j] - oS.alphas[i])</span><br><span class="line">            H = <span class="built_in">min</span>(oS.C, oS.C+oS.alphas[j]-oS.alphas[i])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            L = <span class="built_in">max</span>(<span class="number">0</span>,oS.alphas[j]+oS.alphas[i]-oS.C)</span><br><span class="line">            H = <span class="built_in">min</span>(oS.C,oS.alphas[j]+oS.alphas[i])</span><br><span class="line">        <span class="keyword">if</span> L==H:         <span class="comment"># 如果这个j让L=H,i和j这两个样本是同一类别，且ai=aj=0或ai=aj=C，或者不同类别，aj=C且ai=0</span></span><br><span class="line">                         <span class="comment"># 当同类别时 ai+aj = 常数 ai是不满足KKT的，假设ai=0,需增大它，那么就得减少aj，aj已经是0了，不能最小了，所以此情况不允许发生</span></span><br><span class="line">                         <span class="comment"># 当不同类别时 ai-aj=常数，ai是不满足KKT的，ai=0,aj=C,ai需增大，它则aj也会变大，但是aj已经是C的不能再大了，故此情况不允许</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;L=H&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="comment"># eta = 2.0*oS.K[i,j]-oS.K[i,i]-oS.K[j,j]   # eta=K11+K22-2*K12</span></span><br><span class="line">        eta = <span class="number">2.0</span>*oS.X[i,:]*oS.X[j,:].T - oS.X[i,:]*oS.X[i,:].T - oS.X[j,:]*oS.X[j,:].T</span><br><span class="line">        <span class="keyword">if</span> eta &gt;= <span class="number">0</span>:                 <span class="comment"># 这里跟公式正好差了一个负号，所以对应公式里的 K11+K22-2*K12 &lt;=0，即开口向下，或为0成一条直线的情况不考虑</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;eta&gt;=0&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        oS.alphas[j]-=oS.labelMat[j]*(Ei-Ej)/eta     <span class="comment"># a2^new = a2^old+y2(E1-E2)/eta</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;a2 归约之前是&#123;&#125;&quot;</span>.<span class="built_in">format</span>(oS.alphas[j]))</span><br><span class="line">        oS.alphas[j]=clipAlpha(oS.alphas[j],H,L)     <span class="comment"># 根据公式，看看得到的a2^new是否在上下限之内</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;a2 归约之后is &#123;&#125;&quot;</span>.<span class="built_in">format</span>(oS.alphas[j]))</span><br><span class="line">        <span class="comment"># updateEk(oS,j)               # 把更新后的a2^new的E更新一下</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">abs</span>(oS.alphas[j]-alphaJold)&lt;<span class="number">0.00001</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;j not moving enough&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        oS.alphas[i] +=oS.labelMat[j]*oS.labelMat[i]*(alphaJold-oS.alphas[j])   <span class="comment"># 根据公式a1^new = a1^old+y1*y2*(a2^old-a2^new)</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;a1更新之后是&#123;&#125;&quot;</span>.<span class="built_in">format</span>(oS.alphas[i]))</span><br><span class="line">        <span class="comment"># updateEk(oS,i)</span></span><br><span class="line">        <span class="comment"># b1^new = b1^old+(a1^old-a1^new)y1*K11+(a2^old-a2^new)y2*K12-E1</span></span><br><span class="line">        <span class="comment"># b1 = oS.b-Ei-oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.K[i,i]-oS.labelMat[j]*\</span></span><br><span class="line">        <span class="comment">#      (oS.alphas[j]-alphaJold)*oS.K[i,j]</span></span><br><span class="line"> </span><br><span class="line">        b1 = oS.b-Ei-oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.X[i,:]*oS.X[i,:].T-oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.X[i,:]*oS.X[j,:].T</span><br><span class="line">        <span class="comment"># b2 = oS.b-Ej-oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.K[i,j]-oS.labelMat[j]* \</span></span><br><span class="line">        <span class="comment">#      (oS.alphas[j]-alphaJold)*oS.K[j,j]</span></span><br><span class="line"> </span><br><span class="line">        b2 = oS.b-Ej-oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.X[i,:]*oS.X[j,:].T-oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.X[j,:]*oS.X[j,:].T</span><br><span class="line">        updateEk(oS,j)          <span class="comment"># 个人认为更新误差应在更新b之后，因为公式算出的b的公式使用的是以前的Ei</span></span><br><span class="line">        updateEk(oS,i)</span><br><span class="line">        <span class="comment"># b2^new=b2^old+(a1^old-a1^new)y1*K12+(a2^old-a2^new)y2*K22-E2</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="number">0</span> &lt; oS.alphas[i]) <span class="keyword">and</span> (oS.C &gt; oS.alphas[i]):</span><br><span class="line">            oS.b = b1.A[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">elif</span> (<span class="number">0</span>&lt;oS.alphas[j]) <span class="keyword">and</span> (oS.C &gt; oS.alphas[j]):</span><br><span class="line">            oS.b = b2.A[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            oS.b = (b1+b2)/<span class="number">2.0</span></span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;b is &#123;&#125;&quot;</span>.<span class="built_in">format</span>(oS.b))</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">smoP</span>(<span class="params">dataMatIn, classLabels, C,toler,maxIter,kTup=(<span class="params"><span class="string">&#x27;lin&#x27;</span>,</span>)</span>):</span><br><span class="line">    oS = optStruct(mat(dataMatIn), mat(classLabels).transpose(),C,toler,kTup)</span><br><span class="line">    <span class="built_in">iter</span> = <span class="number">0</span></span><br><span class="line">    entireSet = <span class="literal">True</span>              <span class="comment"># 两种遍历方式交替</span></span><br><span class="line">    alphaPairsChanged = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> (<span class="built_in">iter</span>&lt;maxIter) <span class="keyword">and</span> ((alphaPairsChanged&gt;<span class="number">0</span>) <span class="keyword">or</span> (entireSet)):</span><br><span class="line">        alphaPairsChanged = <span class="number">0</span></span><br><span class="line">        <span class="keyword">if</span> entireSet:</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(oS.m):</span><br><span class="line">                alphaPairsChanged += innerL(i,oS)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;fullSet, iter:%d i: %d pairs changed %d&quot;</span>%(<span class="built_in">iter</span>,i ,alphaPairsChanged))</span><br><span class="line"> </span><br><span class="line">            <span class="built_in">iter</span>+=<span class="number">1</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;第一种遍历alphaRairChanged is &#123;&#125;&quot;</span>.<span class="built_in">format</span>(alphaPairsChanged))</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;-----------eCache is &#123;&#125;&quot;</span>.<span class="built_in">format</span>(oS.eCache))</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;***********alphas is &#123;&#125;&quot;</span>.<span class="built_in">format</span>(oS.alphas))</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;---------------------------------------&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            nonBoundIs = nonzero((oS.alphas.A &gt; <span class="number">0</span>) * (oS.alphas.A &lt; C))[<span class="number">0</span>]  <span class="comment"># 这时数组相乘，里面其实是True 和False的数组，得出来的是</span></span><br><span class="line">                                                                          <span class="comment"># 大于0并且小于C的alpha的下标</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> nonBoundIs:</span><br><span class="line">                alphaPairsChanged += innerL(i,oS)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;non-bound, iter: %d i:%d, pairs changed %d&quot;</span>%(<span class="built_in">iter</span>,i,alphaPairsChanged))</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;第二种遍历alphaPairChanged is &#123;&#125;&quot;</span>.<span class="built_in">format</span>(alphaPairsChanged))</span><br><span class="line">            <span class="built_in">iter</span>+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> entireSet:</span><br><span class="line">            entireSet = <span class="literal">False</span>  <span class="comment"># 当第二种遍历方式alpha不再变化，那么继续第一种方式扫描，第一种方式不再变化，此时alphachanged为0且entireSet为false，退出循环</span></span><br><span class="line">        <span class="keyword">elif</span> (alphaPairsChanged==<span class="number">0</span>):</span><br><span class="line">            entireSet=<span class="literal">True</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;iteration number: %d&quot;</span>%<span class="built_in">iter</span>)</span><br><span class="line">    <span class="keyword">return</span> oS.b,oS.alphas</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calcWs</span>(<span class="params">alphas,dataArr,classLabels</span>):                <span class="comment"># 通过alpha来计算w</span></span><br><span class="line">    X = mat(dataArr)</span><br><span class="line">    labelMat = mat(classLabels).transpose()</span><br><span class="line">    m,n = shape(X)</span><br><span class="line">    w = zeros((n,<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">        w += multiply(alphas[i]*labelMat[i], X[i,:].T)        <span class="comment"># w = sum(ai*yi*xi)</span></span><br><span class="line">    <span class="keyword">return</span> w</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_points</span>(<span class="params">dataArr,classlabel, w,b,alphas</span>):</span><br><span class="line">    myfont = FontProperties(fname=<span class="string">&#x27;/usr/share/fonts/simhei.ttf&#x27;</span>)    <span class="comment"># 显示中文</span></span><br><span class="line">    plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>     <span class="comment"># 防止坐标轴的‘-’变为方块</span></span><br><span class="line">    m = <span class="built_in">len</span>(classlabel)</span><br><span class="line">    red_points_x=[]</span><br><span class="line">    red_points_y =[]</span><br><span class="line">    blue_points_x=[]</span><br><span class="line">    blue_points_y =[]</span><br><span class="line">    svc_points_x =[]</span><br><span class="line">    svc_points_y =[]</span><br><span class="line">    <span class="comment"># print(type(alphas))</span></span><br><span class="line">    svc_point_index = nonzero((alphas.A&gt;<span class="number">0</span>) * (alphas.A &lt;<span class="number">0.8</span>))[<span class="number">0</span>]</span><br><span class="line">    svc_points = array(dataArr)[svc_point_index]</span><br><span class="line">    svc_points_x = [x[<span class="number">0</span>] <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">list</span>(svc_points)]</span><br><span class="line">    svc_points_y = [x[<span class="number">1</span>] <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">list</span>(svc_points)]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;svc_points_x&quot;</span>,svc_points_x)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;svc_points_y&quot;</span>,svc_points_y)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">        <span class="keyword">if</span> classlabel[i] ==<span class="number">1</span>:</span><br><span class="line">            red_points_x.append(dataArr[i][<span class="number">0</span>])</span><br><span class="line">            red_points_y.append(dataArr[i][<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            blue_points_x.append(dataArr[i][<span class="number">0</span>])</span><br><span class="line">            blue_points_y.append(dataArr[i][<span class="number">1</span>])</span><br><span class="line"> </span><br><span class="line">    fig = plt.figure()                     <span class="comment"># 创建画布</span></span><br><span class="line">    ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">    ax.set_title(<span class="string">&quot;SVM-Classify&quot;</span>)           <span class="comment"># 设置图片标题</span></span><br><span class="line">    ax.set_xlabel(<span class="string">&quot;x&quot;</span>)                     <span class="comment"># 设置坐标名称</span></span><br><span class="line">    ax.set_ylabel(<span class="string">&quot;y&quot;</span>)</span><br><span class="line">    ax1=ax.scatter(red_points_x, red_points_y, s=<span class="number">30</span>,c=<span class="string">&#x27;red&#x27;</span>, marker=<span class="string">&#x27;s&#x27;</span>)   <span class="comment">#s是shape大小，c是颜色，marker是形状，&#x27;s&#x27;代表是正方形,默认&#x27;o&#x27;是圆圈</span></span><br><span class="line">    ax2=ax.scatter(blue_points_x, blue_points_y, s=<span class="number">40</span>,c=<span class="string">&#x27;green&#x27;</span>)</span><br><span class="line">    <span class="comment"># ax.set_ylim([-6,5])</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;b&quot;</span>,b)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;w&quot;</span>,w)</span><br><span class="line">    x = arange(-<span class="number">4.0</span>, <span class="number">4.0</span>, <span class="number">0.1</span>)                   <span class="comment"># 分界线x范围,步长为0.1</span></span><br><span class="line">    <span class="comment"># x = arange(-2.0,10.0)</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(b,numpy.matrixlib.defmatrix.matrix):</span><br><span class="line">        b = b.A[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">    y = (-b-w[<span class="number">0</span>][<span class="number">0</span>]*x)/w[<span class="number">1</span>][<span class="number">0</span>]    <span class="comment"># 直线方程 Ax + By + C = 0</span></span><br><span class="line">    ax3,=plt.plot(x,y, <span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">    ax4=plt.scatter(svc_points_x,svc_points_y,s=<span class="number">50</span>,c=<span class="string">&#x27;orange&#x27;</span>,marker=<span class="string">&#x27;p&#x27;</span>)</span><br><span class="line">    plt.legend([ax1, ax2,ax3,ax4], [<span class="string">&quot;red points&quot;</span>,<span class="string">&quot;blue points&quot;</span>, <span class="string">&quot;decision boundary&quot;</span>,<span class="string">&quot;support vector&quot;</span>], loc=<span class="string">&#x27;lower right&#x27;</span>)         <span class="comment"># 标注</span></span><br><span class="line">    plt.show()</span><br><span class="line"> </span><br><span class="line">dataArr,labelArr = loadDataSet(<span class="string">&#x27;/home/zhangqingfeng/test/svm_test_data&#x27;</span>)</span><br><span class="line">b,alphas = smoP(dataArr,labelArr,<span class="number">0.8</span>,<span class="number">0.001</span>,<span class="number">40</span>)</span><br><span class="line">w=calcWs(alphas,dataArr,labelArr)</span><br><span class="line">draw_points(dataArr,labelArr,w,b,alphas)</span><br></pre></td></tr></table></figure>

<h1 id="插值"><a href="#插值" class="headerlink" title="插值"></a>插值</h1><h1 id="一维插值"><a href="#一维插值" class="headerlink" title="一维插值"></a>一维插值</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> interpolate</span><br><span class="line"><span class="keyword">import</span> pylab <span class="keyword">as</span> pl</span><br><span class="line"></span><br><span class="line">x=np.linspace(<span class="number">0</span>,<span class="number">10</span>,<span class="number">11</span>)</span><br><span class="line"><span class="comment">#x=[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.]</span></span><br><span class="line">y=np.sin(x)</span><br><span class="line">xnew=np.linspace(<span class="number">0</span>,<span class="number">10</span>,<span class="number">101</span>)</span><br><span class="line">pl.plot(x,y,<span class="string">&quot;ro&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> kind <span class="keyword">in</span> [<span class="string">&quot;nearest&quot;</span>,<span class="string">&quot;zero&quot;</span>,<span class="string">&quot;slinear&quot;</span>,<span class="string">&quot;quadratic&quot;</span>,<span class="string">&quot;cubic&quot;</span>]:<span class="comment">#插值方式</span></span><br><span class="line">    <span class="comment">#&quot;nearest&quot;,&quot;zero&quot;为阶梯插值</span></span><br><span class="line">    <span class="comment">#slinear 线性插值</span></span><br><span class="line">    <span class="comment">#&quot;quadratic&quot;,&quot;cubic&quot; 为2阶、3阶B样条曲线插值</span></span><br><span class="line">    f=interpolate.interp1d(x,y,kind=kind)</span><br><span class="line">    <span class="comment"># ‘slinear’, ‘quadratic’ and ‘cubic’ refer to a spline interpolation of first, second or third order)</span></span><br><span class="line">    ynew=f(xnew)</span><br><span class="line">    pl.plot(xnew,ynew,label=<span class="built_in">str</span>(kind))</span><br><span class="line">pl.legend(loc=<span class="string">&quot;lower right&quot;</span>)</span><br><span class="line">pl.show()</span><br></pre></td></tr></table></figure>

<h2 id="二维插值"><a href="#二维插值" class="headerlink" title="二维插值"></a>二维插值</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> interpolate</span><br><span class="line"><span class="keyword">import</span> pylab <span class="keyword">as</span> pl</span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">func</span>(<span class="params">x, y</span>):</span><br><span class="line">    <span class="keyword">return</span> (x+y)*np.exp(-<span class="number">5.0</span>*(x**<span class="number">2</span> + y**<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># X-Y轴分为15*15的网格</span></span><br><span class="line">y,x= np.mgrid[-<span class="number">1</span>:<span class="number">1</span>:<span class="number">15j</span>, -<span class="number">1</span>:<span class="number">1</span>:<span class="number">15j</span>]</span><br><span class="line"></span><br><span class="line">fvals = func(x,y) <span class="comment"># 计算每个网格点上的函数值  15*15的值</span></span><br><span class="line"><span class="built_in">print</span> <span class="built_in">len</span>(fvals[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#三次样条二维插值</span></span><br><span class="line">newfunc = interpolate.interp2d(x, y, fvals, kind=<span class="string">&#x27;cubic&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算100*100的网格上的插值</span></span><br><span class="line">xnew = np.linspace(-<span class="number">1</span>,<span class="number">1</span>,<span class="number">100</span>)<span class="comment">#x</span></span><br><span class="line">ynew = np.linspace(-<span class="number">1</span>,<span class="number">1</span>,<span class="number">100</span>)<span class="comment">#y</span></span><br><span class="line">fnew = newfunc(xnew, ynew)<span class="comment">#仅仅是y值   100*100的值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘图</span></span><br><span class="line"><span class="comment"># 为了更明显地比较插值前后的区别，使用关键字参数interpolation=&#x27;nearest&#x27;</span></span><br><span class="line"><span class="comment"># 关闭imshow()内置的插值运算。</span></span><br><span class="line">pl.subplot(<span class="number">121</span>)</span><br><span class="line">im1=pl.imshow(fvals, extent=[-<span class="number">1</span>,<span class="number">1</span>,-<span class="number">1</span>,<span class="number">1</span>], cmap=mpl.cm.hot, interpolation=<span class="string">&#x27;nearest&#x27;</span>, origin=<span class="string">&quot;lower&quot;</span>)<span class="comment">#pl.cm.jet</span></span><br><span class="line"><span class="comment">#extent=[-1,1,-1,1]为x,y范围  favals为</span></span><br><span class="line">pl.colorbar(im1)</span><br><span class="line"></span><br><span class="line">pl.subplot(<span class="number">122</span>)</span><br><span class="line">im2=pl.imshow(fnew, extent=[-<span class="number">1</span>,<span class="number">1</span>,-<span class="number">1</span>,<span class="number">1</span>], cmap=mpl.cm.hot, interpolation=<span class="string">&#x27;nearest&#x27;</span>, origin=<span class="string">&quot;lower&quot;</span>)</span><br><span class="line">pl.colorbar(im2)</span><br><span class="line">pl.show()</span><br></pre></td></tr></table></figure>

<h2 id="二维插值的三维展示方法"><a href="#二维插值的三维展示方法" class="headerlink" title="二维插值的三维展示方法"></a>二维插值的三维展示方法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> interpolate</span><br><span class="line"><span class="keyword">import</span> matplotlib.cm <span class="keyword">as</span> cm</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">func</span>(<span class="params">x, y</span>):</span><br><span class="line">    <span class="keyword">return</span> (x+y)*np.exp(-<span class="number">5.0</span>*(x**<span class="number">2</span> + y**<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># X-Y轴分为20*20的网格</span></span><br><span class="line">x = np.linspace(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">20</span>)</span><br><span class="line">y = np.linspace(-<span class="number">1</span>,<span class="number">1</span>,<span class="number">20</span>)</span><br><span class="line">x, y = np.meshgrid(x, y)<span class="comment">#20*20的网格数据</span></span><br><span class="line"></span><br><span class="line">fvals = func(x,y) <span class="comment"># 计算每个网格点上的函数值  15*15的值</span></span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">9</span>, <span class="number">6</span>))</span><br><span class="line"><span class="comment">#Draw sub-graph1</span></span><br><span class="line">ax=plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>,projection = <span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line">surf = ax.plot_surface(x, y, fvals, rstride=<span class="number">2</span>, cstride=<span class="number">2</span>, cmap=cm.coolwarm,linewidth=<span class="number">0.5</span>, antialiased=<span class="literal">True</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">ax.set_zlabel(<span class="string">&#x27;f(x, y)&#x27;</span>)</span><br><span class="line">plt.colorbar(surf, shrink=<span class="number">0.5</span>, aspect=<span class="number">5</span>)<span class="comment">#标注</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#二维插值</span></span><br><span class="line">newfunc = interpolate.interp2d(x, y, fvals, kind=<span class="string">&#x27;cubic&#x27;</span>)<span class="comment">#newfunc为一个函数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算100*100的网格上的插值</span></span><br><span class="line">xnew = np.linspace(-<span class="number">1</span>,<span class="number">1</span>,<span class="number">100</span>)<span class="comment">#x</span></span><br><span class="line">ynew = np.linspace(-<span class="number">1</span>,<span class="number">1</span>,<span class="number">100</span>)<span class="comment">#y</span></span><br><span class="line">fnew = newfunc(xnew, ynew)<span class="comment">#仅仅是y值   100*100的值  np.shape(fnew) is 100*100</span></span><br><span class="line">xnew, ynew = np.meshgrid(xnew, ynew)</span><br><span class="line">ax2=plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>,projection = <span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line">surf2 = ax2.plot_surface(xnew, ynew, fnew, rstride=<span class="number">2</span>, cstride=<span class="number">2</span>, cmap=cm.coolwarm,linewidth=<span class="number">0.5</span>, antialiased=<span class="literal">True</span>)</span><br><span class="line">ax2.set_xlabel(<span class="string">&#x27;xnew&#x27;</span>)</span><br><span class="line">ax2.set_ylabel(<span class="string">&#x27;ynew&#x27;</span>)</span><br><span class="line">ax2.set_zlabel(<span class="string">&#x27;fnew(x, y)&#x27;</span>)</span><br><span class="line">plt.colorbar(surf2, shrink=<span class="number">0.5</span>, aspect=<span class="number">5</span>)<span class="comment">#标注</span></span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h1 id="灰色预测模型"><a href="#灰色预测模型" class="headerlink" title="灰色预测模型"></a>灰色预测模型</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line">history_data = [<span class="number">724.57</span>,<span class="number">746.62</span>,<span class="number">778.27</span>,<span class="number">800.8</span>,<span class="number">827.75</span>,<span class="number">871.1</span>,<span class="number">912.37</span>,<span class="number">954.28</span>,<span class="number">995.01</span>,<span class="number">1037.2</span>]</span><br><span class="line">n = <span class="built_in">len</span>(history_data)</span><br><span class="line">X0 = np.array(history_data)</span><br><span class="line"></span><br><span class="line"><span class="comment">#累加生成</span></span><br><span class="line">history_data_agg = [<span class="built_in">sum</span>(history_data[<span class="number">0</span>:i+<span class="number">1</span>]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">X1 = np.array(history_data_agg)</span><br><span class="line"></span><br><span class="line"><span class="comment">#计算数据矩阵B和数据向量Y</span></span><br><span class="line">B = np.zeros([n-<span class="number">1</span>,<span class="number">2</span>])</span><br><span class="line">Y = np.zeros([n-<span class="number">1</span>,<span class="number">1</span>])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,n-<span class="number">1</span>):</span><br><span class="line">    B[i][<span class="number">0</span>] = -<span class="number">0.5</span>*(X1[i] + X1[i+<span class="number">1</span>])</span><br><span class="line">    B[i][<span class="number">1</span>] = <span class="number">1</span></span><br><span class="line">    Y[i][<span class="number">0</span>] = X0[i+<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#计算GM(1,1)微分方程的参数a和u</span></span><br><span class="line"><span class="comment">#A = np.zeros([2,1])</span></span><br><span class="line">A = np.linalg.inv(B.T.dot(B)).dot(B.T).dot(Y)</span><br><span class="line">a = A[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">u = A[<span class="number">1</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#建立灰色预测模型</span></span><br><span class="line">XX0 = np.zeros(n)</span><br><span class="line">XX0[<span class="number">0</span>] = X0[<span class="number">0</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n):</span><br><span class="line">    XX0[i] = (X0[<span class="number">0</span>] - u/a)*(<span class="number">1</span>-math.exp(a))*math.exp(-a*(i));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#模型精度的后验差检验</span></span><br><span class="line">e = <span class="number">0</span>      <span class="comment">#求残差平均值</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,n):</span><br><span class="line">    e += (X0[i] - XX0[i])</span><br><span class="line">e /= n</span><br><span class="line"></span><br><span class="line"><span class="comment">#求历史数据平均值</span></span><br><span class="line">aver = <span class="number">0</span>;     </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,n):</span><br><span class="line">    aver += X0[i]</span><br><span class="line">aver /= n</span><br><span class="line"></span><br><span class="line"><span class="comment">#求历史数据方差</span></span><br><span class="line">s12 = <span class="number">0</span>;     </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,n):</span><br><span class="line">    s12 += (X0[i]-aver)**<span class="number">2</span>;</span><br><span class="line">s12 /= n</span><br><span class="line"></span><br><span class="line"><span class="comment">#求残差方差</span></span><br><span class="line">s22 = <span class="number">0</span>;       </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,n):</span><br><span class="line">    s22 += ((X0[i] - XX0[i]) - e)**<span class="number">2</span>;</span><br><span class="line">s22 /= n</span><br><span class="line"></span><br><span class="line"><span class="comment">#求后验差比值</span></span><br><span class="line">C = s22 / s12   </span><br><span class="line"></span><br><span class="line"><span class="comment">#求小误差概率</span></span><br><span class="line">cout = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,n):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">abs</span>((X0[i] - XX0[i]) - e) &lt; <span class="number">0.6754</span>*math.sqrt(s12):</span><br><span class="line">        cout = cout+<span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        cout = cout</span><br><span class="line">P = cout / n</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (C &lt; <span class="number">0.35</span> <span class="keyword">and</span> P &gt; <span class="number">0.95</span>):</span><br><span class="line">    <span class="comment">#预测精度为一级</span></span><br><span class="line">    m = <span class="number">10</span>   <span class="comment">#请输入需要预测的年数</span></span><br><span class="line">    <span class="comment">#print(&#x27;往后m各年负荷为：&#x27;)</span></span><br><span class="line">    f = np.zeros(m)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,m):</span><br><span class="line">        f[i] = (X0[<span class="number">0</span>] - u/a)*(<span class="number">1</span>-math.exp(a))*math.exp(-a*(i+n))    </span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;灰色预测法不适用&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="智能优化之遗传算法"><a href="#智能优化之遗传算法" class="headerlink" title="智能优化之遗传算法"></a>智能优化之遗传算法</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> cm</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"></span><br><span class="line">DNA_SIZE = <span class="number">24</span></span><br><span class="line">POP_SIZE = <span class="number">200</span></span><br><span class="line">CROSSOVER_RATE = <span class="number">0.8</span></span><br><span class="line">MUTATION_RATE = <span class="number">0.005</span></span><br><span class="line">N_GENERATIONS = <span class="number">50</span></span><br><span class="line">X_BOUND = [-<span class="number">3</span>, <span class="number">3</span>]</span><br><span class="line">Y_BOUND = [-<span class="number">3</span>, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">F</span>(<span class="params">x, y</span>):</span><br><span class="line">	<span class="keyword">return</span> <span class="number">3</span>*(<span class="number">1</span>-x)**<span class="number">2</span>*np.exp(-(x**<span class="number">2</span>)-(y+<span class="number">1</span>)**<span class="number">2</span>)- <span class="number">10</span>*(x/<span class="number">5</span> - x**<span class="number">3</span> - y**<span class="number">5</span>)*np.exp(-x**<span class="number">2</span>-y**<span class="number">2</span>)- <span class="number">1</span>/<span class="number">3</span>**np.exp(-(x+<span class="number">1</span>)**<span class="number">2</span> - y**<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_3d</span>(<span class="params">ax</span>):</span><br><span class="line"></span><br><span class="line">	X = np.linspace(*X_BOUND, <span class="number">100</span>)</span><br><span class="line">	Y = np.linspace(*Y_BOUND, <span class="number">100</span>)</span><br><span class="line">	X,Y = np.meshgrid(X, Y)</span><br><span class="line">	Z = F(X, Y)</span><br><span class="line">	ax.plot_surface(X,Y,Z,rstride=<span class="number">1</span>,cstride=<span class="number">1</span>,cmap=cm.coolwarm)</span><br><span class="line">	ax.set_zlim(-<span class="number">10</span>,<span class="number">10</span>)</span><br><span class="line">	ax.set_xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">	ax.set_ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">	ax.set_zlabel(<span class="string">&#x27;z&#x27;</span>)</span><br><span class="line">	plt.pause(<span class="number">3</span>)</span><br><span class="line">	plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_fitness</span>(<span class="params">pop</span>): </span><br><span class="line">    x,y = translateDNA(pop)</span><br><span class="line">	pred = F(x, y)</span><br><span class="line">	<span class="keyword">return</span> (pred - np.<span class="built_in">min</span>(pred)) + <span class="number">1e-3</span> <span class="comment">#减去最小的适应度是为了防止适应度出现负数，通过这一步fitness的范围为[0, np.max(pred)-np.min(pred)],最后在加上一个很小的数防止出现为0的适应度</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">translateDNA</span>(<span class="params">pop</span>): <span class="comment">#pop表示种群矩阵，一行表示一个二进制编码表示的DNA，矩阵的行数为种群数目</span></span><br><span class="line">	x_pop = pop[:,<span class="number">1</span>::<span class="number">2</span>]<span class="comment">#奇数列表示X</span></span><br><span class="line">	y_pop = pop[:,::<span class="number">2</span>] <span class="comment">#偶数列表示y</span></span><br><span class="line">	</span><br><span class="line">	<span class="comment">#pop:(POP_SIZE,DNA_SIZE)*(DNA_SIZE,1) --&gt; (POP_SIZE,1)</span></span><br><span class="line">	x = x_pop.dot(<span class="number">2</span>**np.arange(DNA_SIZE)[::-<span class="number">1</span>])/<span class="built_in">float</span>(<span class="number">2</span>**DNA_SIZE-<span class="number">1</span>)*(X_BOUND[<span class="number">1</span>]-X_BOUND[<span class="number">0</span>])+X_BOUND[<span class="number">0</span>]</span><br><span class="line">	y = y_pop.dot(<span class="number">2</span>**np.arange(DNA_SIZE)[::-<span class="number">1</span>])/<span class="built_in">float</span>(<span class="number">2</span>**DNA_SIZE-<span class="number">1</span>)*(Y_BOUND[<span class="number">1</span>]-Y_BOUND[<span class="number">0</span>])+Y_BOUND[<span class="number">0</span>]</span><br><span class="line">	<span class="keyword">return</span> x,y</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">crossover_and_mutation</span>(<span class="params">pop, CROSSOVER_RATE = <span class="number">0.8</span></span>):</span><br><span class="line">	new_pop = []</span><br><span class="line">	<span class="keyword">for</span> father <span class="keyword">in</span> pop:		<span class="comment">#遍历种群中的每一个个体，将该个体作为父亲</span></span><br><span class="line">		child = father		<span class="comment">#孩子先得到父亲的全部基因（这里我把一串二进制串的那些0，1称为基因）</span></span><br><span class="line">		<span class="keyword">if</span> np.random.rand() &lt; CROSSOVER_RATE:			<span class="comment">#产生子代时不是必然发生交叉，而是以一定的概率发生交叉</span></span><br><span class="line">			mother = pop[np.random.randint(POP_SIZE)]	<span class="comment">#再种群中选择另一个个体，并将该个体作为母亲</span></span><br><span class="line">			cross_points = np.random.randint(low=<span class="number">0</span>, high=DNA_SIZE*<span class="number">2</span>)	<span class="comment">#随机产生交叉的点</span></span><br><span class="line">			child[cross_points:] = mother[cross_points:]		<span class="comment">#孩子得到位于交叉点后的母亲的基因</span></span><br><span class="line">		mutation(child)	<span class="comment">#每个后代有一定的机率发生变异</span></span><br><span class="line">		new_pop.append(child)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> new_pop</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mutation</span>(<span class="params">child, MUTATION_RATE=<span class="number">0.003</span></span>):</span><br><span class="line">	<span class="keyword">if</span> np.random.rand() &lt; MUTATION_RATE: 				<span class="comment">#以MUTATION_RATE的概率进行变异</span></span><br><span class="line">		mutate_point = np.random.randint(<span class="number">0</span>, DNA_SIZE)	<span class="comment">#随机产生一个实数，代表要变异基因的位置</span></span><br><span class="line">		child[mutate_point] = child[mutate_point]^<span class="number">1</span> 	<span class="comment">#将变异点的二进制为反转</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">select</span>(<span class="params">pop, fitness</span>):    <span class="comment"># nature selection wrt pop&#x27;s fitness</span></span><br><span class="line">    idx = np.random.choice(np.arange(POP_SIZE), size=POP_SIZE, replace=<span class="literal">True</span>,</span><br><span class="line">                           p=(fitness)/(fitness.<span class="built_in">sum</span>()) )</span><br><span class="line">    <span class="keyword">return</span> pop[idx]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">print_info</span>(<span class="params">pop</span>):</span><br><span class="line">	fitness = get_fitness(pop)</span><br><span class="line">	max_fitness_index = np.argmax(fitness)</span><br><span class="line">	<span class="built_in">print</span>(<span class="string">&quot;max_fitness:&quot;</span>, fitness[max_fitness_index])</span><br><span class="line">	x,y = translateDNA(pop)</span><br><span class="line">	<span class="built_in">print</span>(<span class="string">&quot;最优的基因型：&quot;</span>, pop[max_fitness_index])</span><br><span class="line">	<span class="built_in">print</span>(<span class="string">&quot;(x, y):&quot;</span>, (x[max_fitness_index], y[max_fitness_index]))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">	fig = plt.figure()</span><br><span class="line">	ax = Axes3D(fig)	</span><br><span class="line">	plt.ion()<span class="comment">#将画图模式改为交互模式，程序遇到plt.show不会暂停，而是继续执行</span></span><br><span class="line">	plot_3d(ax)</span><br><span class="line"></span><br><span class="line">	pop = np.random.randint(<span class="number">2</span>, size=(POP_SIZE, DNA_SIZE*<span class="number">2</span>)) <span class="comment">#matrix (POP_SIZE, DNA_SIZE)</span></span><br><span class="line">	<span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(N_GENERATIONS):<span class="comment">#迭代N代</span></span><br><span class="line">		x,y = translateDNA(pop)</span><br><span class="line">		<span class="keyword">if</span> <span class="string">&#x27;sca&#x27;</span> <span class="keyword">in</span> <span class="built_in">locals</span>(): </span><br><span class="line">			sca.remove()</span><br><span class="line">		sca = ax.scatter(x, y, F(x,y), c=<span class="string">&#x27;black&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>);plt.show();plt.pause(<span class="number">0.1</span>)</span><br><span class="line">		pop = np.array(crossover_and_mutation(pop, CROSSOVER_RATE))</span><br><span class="line">		<span class="comment">#F_values = F(translateDNA(pop)[0], translateDNA(pop)[1])#x, y --&gt; Z matrix</span></span><br><span class="line">		fitness = get_fitness(pop)</span><br><span class="line">		pop = select(pop, fitness) <span class="comment">#选择生成新的种群</span></span><br><span class="line">	</span><br><span class="line">	print_info(pop)</span><br><span class="line">	plt.ioff()</span><br><span class="line">	plot_3d(ax)</span><br></pre></td></tr></table></figure>

<h1 id="TOPSIS综合评价模型"><a href="#TOPSIS综合评价模型" class="headerlink" title="TOPSIS综合评价模型"></a>TOPSIS综合评价模型</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># 导入 numpy 包并将其命名为 np</span></span><br><span class="line"><span class="comment"># 定义正向化的函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">positivization</span>(<span class="params">x,<span class="built_in">type</span>,i</span>):</span><br><span class="line"><span class="comment"># x：需要正向化处理的指标对应的原始向量</span></span><br><span class="line"><span class="comment"># typ：指标类型（1：极小型，2：中间型，3：区间型）</span></span><br><span class="line"><span class="comment"># i：正在处理的是原始矩阵的哪一列</span></span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">type</span> == <span class="number">1</span>: <span class="comment">#极小型</span></span><br><span class="line">		<span class="built_in">print</span>(<span class="string">&quot;第&quot;</span>,i,<span class="string">&quot;列是极小型，正向化中...&quot;</span>)</span><br><span class="line">		posit_x = x.<span class="built_in">max</span>(<span class="number">0</span>)-x</span><br><span class="line">		<span class="built_in">print</span>(<span class="string">&quot;第&quot;</span>,i,<span class="string">&quot;列极小型处理完成&quot;</span>)</span><br><span class="line">		<span class="built_in">print</span>(<span class="string">&quot;--------------------------分隔--------------------------&quot;</span>)</span><br><span class="line">	<span class="keyword">return</span> posit_x</span><br><span class="line"><span class="keyword">elif</span> <span class="built_in">type</span> == <span class="number">2</span>: <span class="comment">#中间型</span></span><br><span class="line">	<span class="built_in">print</span>(<span class="string">&quot;第&quot;</span>,i,<span class="string">&quot;列是中间型&quot;</span>)</span><br><span class="line">	best = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;请输入最佳值：&quot;</span>))</span><br><span class="line">	m = (<span class="built_in">abs</span>(x-best)).<span class="built_in">max</span>()</span><br><span class="line">	posit_x = <span class="number">1</span>-<span class="built_in">abs</span>(x-best)/m</span><br><span class="line">	<span class="built_in">print</span>(<span class="string">&quot;第&quot;</span>,i,<span class="string">&quot;列中间型处理完成&quot;</span>)</span><br><span class="line">	<span class="built_in">print</span>(<span class="string">&quot;--------------------------分隔--------------------------&quot;</span>)</span><br><span class="line">	<span class="keyword">return</span> posit_x</span><br><span class="line"><span class="keyword">elif</span> <span class="built_in">type</span> == <span class="number">3</span>: <span class="comment">#区间型</span></span><br><span class="line">	<span class="built_in">print</span>(<span class="string">&quot;第&quot;</span>,i,<span class="string">&quot;列是区间型&quot;</span>)</span><br><span class="line">	a,b = [<span class="built_in">int</span>(l) <span class="keyword">for</span> l <span class="keyword">in</span> <span class="built_in">input</span>(<span class="string">&quot;按顺序输入最佳区间的左右界，并用逗号隔开：&quot;</span>).split(<span class="string">&quot;,&quot;</span>)]</span><br><span class="line">	m = (np.append(a-x.<span class="built_in">min</span>(),x.<span class="built_in">max</span>()-b)).<span class="built_in">max</span>()</span><br><span class="line">	x_row = x.shape[<span class="number">0</span>] <span class="comment">#获取 x 的行数</span></span><br><span class="line">	posit_x = np.zeros((x_row,<span class="number">1</span>),dtype=<span class="built_in">float</span>)</span><br><span class="line"><span class="keyword">for</span> r <span class="keyword">in</span> <span class="built_in">range</span>(x_row):</span><br><span class="line">	<span class="keyword">if</span> x[r] &lt; a:</span><br><span class="line">		posit_x[r] = <span class="number">1</span>-(a-x[r])/m</span><br><span class="line">	<span class="keyword">elif</span> x[r] &gt; b:</span><br><span class="line">		posit_x[r] = <span class="number">1</span>-(x[r]-b)/m</span><br><span class="line">	<span class="keyword">else</span>:</span><br><span class="line">		posit_x[r] = <span class="number">1</span></span><br><span class="line">		<span class="built_in">print</span>(<span class="string">&quot;第&quot;</span>,i,<span class="string">&quot;列区间型处理完成&quot;</span>)</span><br><span class="line">		<span class="built_in">print</span>(<span class="string">&quot;--------------------------分隔--------------------------&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> posit_x.reshape(x_row)</span><br><span class="line"><span class="comment">## 第一步：从外部导入数据</span></span><br><span class="line"><span class="comment"># 注：保证表格不包含除数字以外的内容</span></span><br><span class="line">x_mat = np.loadtxt(<span class="string">&#x27;river.csv&#x27;</span>, encoding=<span class="string">&#x27;UTF-8-sig&#x27;</span>, delimiter=<span class="string">&#x27;,&#x27;</span>) <span class="comment"># 推荐使用 csv 格式文件</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 第二步：判断是否需要正向化</span></span><br><span class="line">n, m = x_mat.shape</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;共有&quot;</span>, n, <span class="string">&quot;个评价对象&quot;</span>, m, <span class="string">&quot;个评价指标&quot;</span>)</span><br><span class="line">judge = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;指标是否需要正向化处理，需要请输入 1，不需要则输入 0：&quot;</span>))</span><br><span class="line"><span class="keyword">if</span> judge == <span class="number">1</span>:</span><br><span class="line">	position = np.array([<span class="built_in">int</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">input</span>(<span class="string">&quot;请输入需要正向化处理的指标所在的列，例如第 1、3、4 列需要处理，则输入 1,3,4&quot;</span>).split(<span class="string">&#x27;,&#x27;</span>)])</span><br><span class="line">	position = position-<span class="number">1</span></span><br><span class="line">	typ = np.array([<span class="built_in">int</span>(j) <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">input</span>(<span class="string">&quot;请按照顺序输入这些列的指标类型（1：极小型，2：中间型，3：区间型）格式同上&quot;</span>).split(<span class="string">&#x27;,&#x27;</span>)])</span><br><span class="line">	<span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(position.shape[<span class="number">0</span>]):</span><br><span class="line">		x_mat[:, position[k]] = positivization(x_mat[:, 			position[k]], typ[k], position[k])</span><br><span class="line">		<span class="built_in">print</span>(<span class="string">&quot;正向化后的矩阵：&quot;</span>, x_mat)</span><br><span class="line"><span class="comment">## 第三步：对正向化后的矩阵进行标准化</span></span><br><span class="line">tep_x1 = (x_mat * x_mat).<span class="built_in">sum</span>(axis=<span class="number">0</span>) <span class="comment"># 每个元素平方后按列相加</span></span><br><span class="line">tep_x2 = np.tile(tep_x1, (n, <span class="number">1</span>)) <span class="comment"># 将矩阵 tep_x1 平铺 n 行</span></span><br><span class="line">Z = x_mat / ((tep_x2) ** <span class="number">0.5</span>) <span class="comment"># Z 为标准化矩阵</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;标准化后的矩阵为：&quot;</span>, Z)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 第四步：计算与最大值和最小值的距离，并算出得分</span></span><br><span class="line">tep_max = Z.<span class="built_in">max</span>(<span class="number">0</span>) <span class="comment"># 得到 Z 中每列的最大值</span></span><br><span class="line">tep_min = Z.<span class="built_in">min</span>(<span class="number">0</span>) <span class="comment"># 每列的最小值</span></span><br><span class="line">tep_a = Z - np.tile(tep_max, (n, <span class="number">1</span>)) <span class="comment"># 将 tep_max 向下平铺 n 行,并与 Z 中的每个对应元素做差</span></span><br><span class="line">tep_i = Z - np.tile(tep_min, (n, <span class="number">1</span>)) <span class="comment"># 将 tep_max 向下平铺 n 行，并与 Z 中的每个对应元素做差</span></span><br><span class="line">D_P = ((tep_a ** <span class="number">2</span>).<span class="built_in">sum</span>(axis=<span class="number">1</span>)) ** <span class="number">0.5</span> <span class="comment"># D+与最大值的距离向量</span></span><br><span class="line">D_N = ((tep_i ** <span class="number">2</span>).<span class="built_in">sum</span>(axis=<span class="number">1</span>)) ** <span class="number">0.5</span></span><br><span class="line">S = D_N / (D_P + D_N) <span class="comment"># 未归一化的得分</span></span><br><span class="line">std_S = S / S.<span class="built_in">sum</span>(axis=<span class="number">0</span>)</span><br><span class="line">sorted_S = np.sort(std_S, axis=<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(std_S) <span class="comment"># 打印标准化后的得分</span></span><br><span class="line"><span class="comment">## std_S.to_csv(std_S.csv) 结果输出到 std_S.csv 文件</span></span><br></pre></td></tr></table></figure>

<h1 id="逻辑回归模型"><a href="#逻辑回归模型" class="headerlink" title="逻辑回归模型"></a>逻辑回归模型</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">path=<span class="string">&#x27;data&#x27;</span>+os.sep+<span class="string">&#x27;Logireg_data.txt&#x27;</span></span><br><span class="line">pdData=pd.read_csv(path,header=<span class="literal">None</span>,names=[<span class="string">&#x27;Exam1&#x27;</span>,<span class="string">&#x27;Exam2&#x27;</span>,<span class="string">&#x27;Admitted&#x27;</span>])</span><br><span class="line">pdData.head()</span><br><span class="line"><span class="built_in">print</span>(pdData.head())</span><br><span class="line"><span class="built_in">print</span>(pdData.shape)</span><br><span class="line">positive=pdData[pdData[<span class="string">&#x27;Admitted&#x27;</span>]==<span class="number">1</span>]<span class="comment">#定义正</span></span><br><span class="line">nagative=pdData[pdData[<span class="string">&#x27;Admitted&#x27;</span>]==<span class="number">0</span>]<span class="comment">#定义负</span></span><br><span class="line">fig,ax=plt.subplots(figsize=(<span class="number">10</span>,<span class="number">5</span>))</span><br><span class="line">ax.scatter(positive[<span class="string">&#x27;Exam1&#x27;</span>],positive[<span class="string">&#x27;Exam2&#x27;</span>],s=<span class="number">30</span>,c=<span class="string">&#x27;b&#x27;</span>,marker=<span class="string">&#x27;o&#x27;</span>,label=<span class="string">&#x27;Admitted&#x27;</span>)</span><br><span class="line">ax.scatter(nagative[<span class="string">&#x27;Exam1&#x27;</span>],nagative[<span class="string">&#x27;Exam2&#x27;</span>],s=<span class="number">30</span>,c=<span class="string">&#x27;r&#x27;</span>,marker=<span class="string">&#x27;x&#x27;</span>,label=<span class="string">&#x27;not Admitted&#x27;</span>)</span><br><span class="line">ax.legend()</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;Exam 1 score&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;Exam 2 score&#x27;</span>)</span><br><span class="line">plt.show()<span class="comment">#画图</span></span><br><span class="line"><span class="comment">##实现算法 the logistics regression 目标建立一个分类器 设置阈值来判断录取结果</span></span><br><span class="line"><span class="comment">##sigmoid 函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">z</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/(<span class="number">1</span>+np.exp(-z))</span><br><span class="line"><span class="comment">#画图</span></span><br><span class="line">nums=np.arange(-<span class="number">10</span>,<span class="number">10</span>,step=<span class="number">1</span>)</span><br><span class="line">fig,ax=plt.subplots(figsize=(<span class="number">12</span>,<span class="number">4</span>))</span><br><span class="line">ax.plot(nums,sigmoid(nums),<span class="string">&#x27;r&#x27;</span>)<span class="comment">#画图定义</span></span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment">#按照理论实现预测函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">model</span>(<span class="params">X,theta</span>):</span><br><span class="line">    <span class="keyword">return</span> sigmoid(np.dot(X,theta.T))</span><br><span class="line"> </span><br><span class="line">pdData.insert(<span class="number">0</span>,<span class="string">&#x27;ones&#x27;</span>,<span class="number">1</span>)<span class="comment">#插入一列</span></span><br><span class="line">orig_data=pdData.as_matrix()</span><br><span class="line">cols=orig_data.shape[<span class="number">1</span>]</span><br><span class="line">X=orig_data[:,<span class="number">0</span>:cols-<span class="number">1</span>]</span><br><span class="line">y=orig_data[:,cols-<span class="number">1</span>:cols]</span><br><span class="line">theta=np.zeros([<span class="number">1</span>,<span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(X[:<span class="number">5</span>])</span><br><span class="line"><span class="built_in">print</span>(X.shape,y.shape,theta.shape)</span><br><span class="line"><span class="comment">##损失函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cost</span>(<span class="params">X,y,theta</span>):</span><br><span class="line">    left=np.multiply(-y,np.log(model(X,theta)))</span><br><span class="line">    right=np.multiply(<span class="number">1</span>-y,np.log(<span class="number">1</span>-model(X,theta)))</span><br><span class="line">    <span class="keyword">return</span> np.<span class="built_in">sum</span>(left-right)/(<span class="built_in">len</span>(X))</span><br><span class="line"><span class="built_in">print</span>(cost(X,y,theta))</span><br><span class="line"> </span><br><span class="line"><span class="comment">#计算梯度</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient</span>(<span class="params">X, y, theta</span>):</span><br><span class="line">    grad = np.zeros(theta.shape)</span><br><span class="line">    error = (model(X, theta) - y).ravel()</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(theta.ravel())):  <span class="comment"># for each parmeter</span></span><br><span class="line">        term = np.multiply(error, X[:, j])</span><br><span class="line">        grad[<span class="number">0</span>, j] = np.<span class="built_in">sum</span>(term) / <span class="built_in">len</span>(X)</span><br><span class="line">    <span class="keyword">return</span> grad</span><br><span class="line"><span class="comment">##比较3种不同梯度下降方法</span></span><br><span class="line">STOP_ITER=<span class="number">0</span></span><br><span class="line">STOP_COST=<span class="number">1</span></span><br><span class="line">STOP_GRAD=<span class="number">2</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stopCriterion</span>(<span class="params"><span class="built_in">type</span>,value,threshold</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>==STOP_ITER: <span class="keyword">return</span> value&gt;threshold</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">type</span>==STOP_COST: <span class="keyword">return</span> <span class="built_in">abs</span>(value[-<span class="number">1</span>]-value[-<span class="number">2</span>])&lt;threshold</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">type</span>==STOP_GRAD: <span class="keyword">return</span> np.linalg.norm(value)&lt;threshold</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> numpy.random</span><br><span class="line"><span class="comment">#打乱数据洗牌</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">shuffledata</span>(<span class="params">data</span>):</span><br><span class="line">    np.random.shuffle(data)</span><br><span class="line">    cols=data.shape[<span class="number">1</span>]</span><br><span class="line">    X=data[:,<span class="number">0</span>:cols-<span class="number">1</span>]</span><br><span class="line">    y=data[:,cols-<span class="number">1</span>:]</span><br><span class="line">    <span class="keyword">return</span> X,y</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">descent</span>(<span class="params">data, theta, batchSize, stopType, thresh, alpha</span>):</span><br><span class="line">    <span class="comment"># 梯度下降求解</span></span><br><span class="line"> </span><br><span class="line">    init_time = time.time()</span><br><span class="line">    i = <span class="number">0</span>  <span class="comment"># 迭代次数</span></span><br><span class="line">    k = <span class="number">0</span>  <span class="comment"># batch</span></span><br><span class="line">    X, y = shuffledata(data)</span><br><span class="line">    grad = np.zeros(theta.shape)  <span class="comment"># 计算的梯度</span></span><br><span class="line">    costs = [cost(X, y, theta)]  <span class="comment"># 损失值</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        grad = gradient(X[k:k + batchSize], y[k:k + batchSize], theta)</span><br><span class="line">        k += batchSize  <span class="comment"># 取batch数量个数据</span></span><br><span class="line">        <span class="keyword">if</span> k &gt;= n:</span><br><span class="line">            k = <span class="number">0</span></span><br><span class="line">            X, y = shuffledata(data)  <span class="comment"># 重新洗牌</span></span><br><span class="line">        theta = theta - alpha * grad  <span class="comment"># 参数更新</span></span><br><span class="line">        costs.append(cost(X, y, theta))  <span class="comment"># 计算新的损失</span></span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line"> </span><br><span class="line">        <span class="keyword">if</span> stopType == STOP_ITER:</span><br><span class="line">            value = i</span><br><span class="line">        <span class="keyword">elif</span> stopType == STOP_COST:</span><br><span class="line">            value = costs</span><br><span class="line">        <span class="keyword">elif</span> stopType == STOP_GRAD:</span><br><span class="line">            value = grad</span><br><span class="line">        <span class="keyword">if</span> stopCriterion(stopType, value, thresh): <span class="keyword">break</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> theta, i - <span class="number">1</span>, costs, grad, time.time() - init_time</span><br><span class="line"><span class="comment">#选择梯度下降</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">runExpe</span>(<span class="params">data, theta, batchSize, stopType, thresh, alpha</span>):</span><br><span class="line">    <span class="comment">#import pdb; pdb.set_trace();</span></span><br><span class="line">    theta, <span class="built_in">iter</span>, costs, grad, dur = descent(data, theta, batchSize, stopType, thresh, alpha)</span><br><span class="line">    name = <span class="string">&quot;Original&quot;</span> <span class="keyword">if</span> (data[:,<span class="number">1</span>]&gt;<span class="number">2</span>).<span class="built_in">sum</span>() &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="string">&quot;Scaled&quot;</span></span><br><span class="line">    name += <span class="string">&quot; data - learning rate: &#123;&#125; - &quot;</span>.<span class="built_in">format</span>(alpha)</span><br><span class="line">    <span class="keyword">if</span> batchSize==n: strDescType = <span class="string">&quot;Gradient&quot;</span></span><br><span class="line">    <span class="keyword">elif</span> batchSize==<span class="number">1</span>:  strDescType = <span class="string">&quot;Stochastic&quot;</span></span><br><span class="line">    <span class="keyword">else</span>: strDescType = <span class="string">&quot;Mini-batch (&#123;&#125;)&quot;</span>.<span class="built_in">format</span>(batchSize)</span><br><span class="line">    name += strDescType + <span class="string">&quot; descent - Stop: &quot;</span></span><br><span class="line">    <span class="keyword">if</span> stopType == STOP_ITER: strStop = <span class="string">&quot;&#123;&#125; iterations&quot;</span>.<span class="built_in">format</span>(thresh)</span><br><span class="line">    <span class="keyword">elif</span> stopType == STOP_COST: strStop = <span class="string">&quot;costs change &lt; &#123;&#125;&quot;</span>.<span class="built_in">format</span>(thresh)</span><br><span class="line">    <span class="keyword">else</span>: strStop = <span class="string">&quot;gradient norm &lt; &#123;&#125;&quot;</span>.<span class="built_in">format</span>(thresh)</span><br><span class="line">    name += strStop</span><br><span class="line">    <span class="built_in">print</span> (<span class="string">&quot;***&#123;&#125;\nTheta: &#123;&#125; - Iter: &#123;&#125; - Last cost: &#123;:03.2f&#125; - Duration: &#123;:03.2f&#125;s&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line">        name, theta, <span class="built_in">iter</span>, costs[-<span class="number">1</span>], dur))</span><br><span class="line">    fig, ax = plt.subplots(figsize=(<span class="number">12</span>,<span class="number">4</span>))</span><br><span class="line">    ax.plot(np.arange(<span class="built_in">len</span>(costs)), costs, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    ax.set_xlabel(<span class="string">&#x27;Iterations&#x27;</span>)</span><br><span class="line">    ax.set_ylabel(<span class="string">&#x27;Cost&#x27;</span>)</span><br><span class="line">    ax.set_title(name.upper() + <span class="string">&#x27; - Error vs. Iteration&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> theta</span><br><span class="line">n= <span class="number">100</span></span><br><span class="line">runExpe(orig_data,theta,n,STOP_ITER,thresh=<span class="number">5000</span>,alpha=<span class="number">0.000001</span>)</span><br><span class="line">plt.show()</span><br><span class="line">runExpe(orig_data,theta,n,STOP_GRAD,thresh=<span class="number">0.05</span>,alpha=<span class="number">0.001</span>)</span><br><span class="line">plt.show()</span><br><span class="line">runExpe(orig_data,theta,n,STOP_COST,thresh=<span class="number">0.000001</span>,alpha=<span class="number">0.001</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment">#对比</span></span><br><span class="line">runExpe(orig_data, theta, <span class="number">1</span>, STOP_ITER, thresh=<span class="number">5000</span>, alpha=<span class="number">0.001</span>)</span><br><span class="line">plt.show()</span><br><span class="line">runExpe(orig_data, theta, <span class="number">1</span>, STOP_ITER, thresh=<span class="number">15000</span>, alpha=<span class="number">0.000002</span>)</span><br><span class="line">plt.show()</span><br><span class="line">runExpe(orig_data, theta, <span class="number">16</span>, STOP_ITER, thresh=<span class="number">15000</span>, alpha=<span class="number">0.001</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment">##对数据进行标准化 将数据按其属性(按列进行)减去其均值，然后除以其方差。</span></span><br><span class="line"><span class="comment">#最后得到的结果是，对每个属性/每列来说所有数据都聚集在0附近，方差值为1</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing <span class="keyword">as</span> pp</span><br><span class="line"> </span><br><span class="line">scaled_data = orig_data.copy()</span><br><span class="line">scaled_data[:, <span class="number">1</span>:<span class="number">3</span>] = pp.scale(orig_data[:, <span class="number">1</span>:<span class="number">3</span>])</span><br><span class="line"> </span><br><span class="line">runExpe(scaled_data, theta, n, STOP_ITER, thresh=<span class="number">5000</span>, alpha=<span class="number">0.001</span>)</span><br><span class="line"><span class="comment">#设定阈值</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">X, theta</span>):</span><br><span class="line">    <span class="keyword">return</span> [<span class="number">1</span> <span class="keyword">if</span> x &gt;= <span class="number">0.5</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> x <span class="keyword">in</span> model(X, theta)]</span><br><span class="line"> </span><br><span class="line"><span class="comment"># if __name__==&#x27;__main__&#x27;:</span></span><br><span class="line"> </span><br><span class="line">scaled_X = scaled_data[:, :<span class="number">3</span>]</span><br><span class="line">y = scaled_data[:, <span class="number">3</span>]</span><br><span class="line">predictions = predict(scaled_X, theta)</span><br><span class="line">correct = [<span class="number">1</span> <span class="keyword">if</span> ((a == <span class="number">1</span> <span class="keyword">and</span> b == <span class="number">1</span>) <span class="keyword">or</span> (a == <span class="number">0</span> <span class="keyword">and</span> b == <span class="number">0</span>)) <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> (a, b) <span class="keyword">in</span> <span class="built_in">zip</span>(predictions, y)]</span><br><span class="line">accuracy = (<span class="built_in">sum</span>(<span class="built_in">map</span>(<span class="built_in">int</span>, correct)) % <span class="built_in">len</span>(correct))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&#x27;accuracy = &#123;0&#125;%&#x27;</span>.<span class="built_in">format</span>(accuracy))</span><br></pre></td></tr></table></figure>

<h1 id="决策树分类模型"><a href="#决策树分类模型" class="headerlink" title="决策树分类模型"></a>决策树分类模型</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这个监督式学习算法通常被用于分类问题。令人惊奇的是，它同时适用于分类变量和连续因变量。在这个算法中，我们将总体分成两个或更多的同类群。这是根据最重要的属性或者自变量来分成尽可能不同的组别。想要知道更多，可以阅读：简化决策树。</span></span><br><span class="line"><span class="comment"># 在上图中你可以看到，根据多种属性，人群被分成了不同的四个小组，来判断 “他们会不会去玩”。为了把总体分成不同组别，需要用到许多技术，比如说 Gini、Information Gain、Chi-square、entropy。</span></span><br><span class="line"><span class="comment"># 理解决策树工作机制的最好方式是玩Jezzball，一个微软的经典游戏(见下图)。这个游戏的最终目的，是在一个可以移动墙壁的房间里，通过造墙来分割出没有小球的、尽量大的空间。</span></span><br><span class="line"><span class="comment"># 因此，每一次你用墙壁来分隔房间时，都是在尝试着在同一间房里创建两个不同的总体。相似地，决策树也在把总体尽量分割到不同的组里去。</span></span><br><span class="line"><span class="keyword">from</span> sklearn importtree<span class="comment">#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Create tree objectmodel=tree.DecisionTreeClassifier(criterion=&#x27;gini&#x27;)#for classification, here you can change the algorithm as gini or entropy (information gain) by default it is gini</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># model = tree.DecisionTreeRegressor() forregression# Train the model using the training sets andcheck score</span></span><br><span class="line"></span><br><span class="line">model.fit(X,y)</span><br><span class="line">model.score(X,y)<span class="comment">#Predict</span></span><br><span class="line">predicted=model.predict(x_test)</span><br><span class="line">R code</span><br><span class="line">library(rpart)</span><br><span class="line">x</span><br><span class="line"><span class="comment"># grow tree</span></span><br><span class="line">fit</span><br><span class="line"><span class="comment">#Predict Output</span></span><br><span class="line">predicted= predict(fit,x_test)</span><br></pre></td></tr></table></figure>

<h1 id="智能优化之模拟退火算法"><a href="#智能优化之模拟退火算法" class="headerlink" title="智能优化之模拟退火算法"></a>智能优化之模拟退火算法</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#本功能实现最小值的求解#</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line">plt.ion()<span class="comment">#这里需要把matplotlib改为交互状态</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#初始值设定</span></span><br><span class="line">hi=<span class="number">3</span></span><br><span class="line">lo=-<span class="number">3</span></span><br><span class="line">alf=<span class="number">0.95</span></span><br><span class="line">T=<span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#目标函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">11</span>*np.sin(x)+<span class="number">7</span>*np.cos(<span class="number">5</span>*x)<span class="comment">##注意这里要是np.sin</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#可视化函数（开始清楚一次然后重复的画）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">visual</span>(<span class="params">x</span>):</span><br><span class="line">    plt.cla()</span><br><span class="line">    plt.axis([lo-<span class="number">1</span>,hi+<span class="number">1</span>,-<span class="number">20</span>,<span class="number">20</span>])</span><br><span class="line">    m=np.arange(lo,hi,<span class="number">0.0001</span>)</span><br><span class="line">    plt.plot(m,f(m))</span><br><span class="line">    plt.plot(x,f(x),marker=<span class="string">&#x27;o&#x27;</span>,color=<span class="string">&#x27;black&#x27;</span>,markersize=<span class="string">&#x27;4&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;temperature=&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(T))</span><br><span class="line">    plt.pause(<span class="number">0.1</span>)<span class="comment">#如果不停啥都看不见</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#随机产生初始值</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init</span>():</span><br><span class="line">    <span class="keyword">return</span> random.uniform(lo,hi)</span><br><span class="line"></span><br><span class="line"><span class="comment">#新解的随机产生</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">new</span>(<span class="params">x</span>):</span><br><span class="line">    x1=x+T*random.uniform(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> (x1&lt;=hi)&amp;(x1&gt;=lo):</span><br><span class="line">        <span class="keyword">return</span> x1</span><br><span class="line">    <span class="keyword">elif</span> x1&lt;lo:</span><br><span class="line">        rand=random.uniform(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> rand*lo+(<span class="number">1</span>-rand)*x</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        rand=random.uniform(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> rand*hi+(<span class="number">1</span>-rand)*x</span><br><span class="line"></span><br><span class="line"><span class="comment">#p函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">p</span>(<span class="params">x,x1</span>):</span><br><span class="line">    <span class="keyword">return</span> math.exp(-<span class="built_in">abs</span>(f(x)-f(x1))/T)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="keyword">global</span> x</span><br><span class="line">    <span class="keyword">global</span> T</span><br><span class="line">    x=init()</span><br><span class="line">    <span class="keyword">while</span> T&gt;<span class="number">0.0001</span>:</span><br><span class="line">        visual(x)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">500</span>):</span><br><span class="line">            x1=new(x)</span><br><span class="line">            <span class="keyword">if</span> f(x1)&lt;=f(x):</span><br><span class="line">                x=x1</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> random.random()&lt;=p(x,x1):</span><br><span class="line">                    x=x1</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">        T=T*alf</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;最小值为：&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(f(x)))</span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure>

<h1 id="模糊综合评价"><a href="#模糊综合评价" class="headerlink" title="模糊综合评价"></a>模糊综合评价</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#模糊综合评价，计算模糊矩阵和指标权重</span></span><br><span class="line"><span class="keyword">import</span> xlrd</span><br><span class="line">data=xlrd.open_workbook(<span class="string">r&#x27;F:\hufengling\离线数据（更新）\3.xlsx&#x27;</span>) <span class="comment">#读取研究数据</span></span><br><span class="line"><span class="comment"># table1 = data.sheets()[0]          #通过索引顺序获取</span></span><br><span class="line"><span class="comment"># table1 = data.sheet_by_index(sheet_indx)) #通过索引顺序获取</span></span><br><span class="line">table2 = data.sheet_by_name(<span class="string">&#x27;4day&#x27;</span>)<span class="comment">#通过名称获取</span></span><br><span class="line"><span class="comment"># rows = table2.row_values(3) # 获取第四行内容</span></span><br><span class="line">cols1 = table2.col_values(<span class="number">0</span>) <span class="comment"># 获取第1列内容，评价指标1</span></span><br><span class="line">cols2 = table2.col_values(<span class="number">1</span>) <span class="comment">#评价指标2</span></span><br><span class="line">nrow=table2.nrows <span class="comment">#获取总行数</span></span><br><span class="line"><span class="built_in">print</span>(nrow)</span><br><span class="line"><span class="comment">#分为四个等级，优、良、中、差，两个评价指标</span></span><br><span class="line">u1=<span class="number">0</span>;u2=<span class="number">0</span>;u3=<span class="number">0</span>;u4=<span class="number">0</span>  <span class="comment">#用于计算每个等级下的个数，指标1</span></span><br><span class="line">t1=<span class="number">0</span>;t2=<span class="number">0</span>;t3=<span class="number">0</span>;t4=<span class="number">0</span>  <span class="comment">#指标2</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(nrow):</span><br><span class="line">    <span class="keyword">if</span> cols1[i]&lt;=<span class="number">0.018</span>:u1+=<span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> cols1[i]&lt;=<span class="number">0.028</span>:u2+=<span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> cols1[i]&lt;=<span class="number">0.038</span>:u3+=<span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>: u4+=<span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(u1,u2,u3,u4)</span><br><span class="line"><span class="comment">#每个等级下的概率</span></span><br><span class="line">pu1=u1/nrow;pu2=u2/nrow;pu3=u3/nrow;pu4=u4/nrow</span><br><span class="line"><span class="built_in">print</span>(pu1,pu2,pu3,pu4)</span><br><span class="line">du=[pu1,pu2,pu3,pu4]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(nrow):</span><br><span class="line">    <span class="keyword">if</span> cols2[i]&lt;=<span class="number">1</span>:t1+=<span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> cols2[i]&lt;=<span class="number">2</span>:t2+=<span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> cols2[i]&lt;=<span class="number">3</span>:t3+=<span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>: t4+=<span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(t1,t2,t3,t4)</span><br><span class="line">pt1=t1/nrow;pt2=t2/nrow;pt3=t3/nrow;pt4=t4/nrow</span><br><span class="line"><span class="built_in">print</span>(pt1,pt2,pt3,pt4)</span><br><span class="line">dt=[pt1,pt2,pt3,pt4]</span><br><span class="line"></span><br><span class="line"><span class="comment">#熵权法定义指标权重</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">weight</span>(<span class="params">du,dt</span>):</span><br><span class="line">    <span class="keyword">import</span> math</span><br><span class="line">    k=-<span class="number">1</span>/math.log(<span class="number">4</span>)</span><br><span class="line">    sumpu=<span class="number">0</span>;sumpt=<span class="number">0</span>;su=<span class="number">0</span>;st=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">        <span class="keyword">if</span> du[i]==<span class="number">0</span>:su=<span class="number">0</span></span><br><span class="line">        <span class="keyword">else</span>:su=du[i]*math.log(du[i])</span><br><span class="line">        sumpu+=su</span><br><span class="line">        <span class="keyword">if</span> dt[i]==<span class="number">0</span>:st=<span class="number">0</span></span><br><span class="line">        <span class="keyword">else</span>:st=dt[i]*math.log(dt[i])</span><br><span class="line">        sumpt+=st</span><br><span class="line">    E1=k*sumpu;E2=k*sumpt</span><br><span class="line">    E=E1+E2</span><br><span class="line">    w1=(<span class="number">1</span>-E1)/(<span class="number">2</span>-E);w2=(<span class="number">1</span>-E2)/(<span class="number">2</span>-E)</span><br><span class="line">    <span class="keyword">return</span> w1,w2</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">score</span>(<span class="params">du,dt,w1,w2</span>):</span><br><span class="line">    eachS=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">        eachS.append(du[i]*w1+dt[i]*w2)</span><br><span class="line">    <span class="keyword">return</span> eachS</span><br><span class="line">w1,w2=weight(du,dt)</span><br><span class="line">S=score(du,dt,w1,w2) </span><br><span class="line"><span class="comment">#S中含有四个值，分别对应四个等级，取其中最大的值对应的等级即是最后的评价结果</span></span><br><span class="line"><span class="built_in">print</span>(w1,w2)</span><br><span class="line"><span class="built_in">print</span>(S)</span><br></pre></td></tr></table></figure>

<h1 id="层次分析法"><a href="#层次分析法" class="headerlink" title="层次分析法"></a>层次分析法</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AHP</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    相关信息的传入和准备</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, array</span>):</span><br><span class="line">        <span class="comment">## 记录矩阵相关信息</span></span><br><span class="line">        self.array = array</span><br><span class="line">        <span class="comment">## 记录矩阵大小</span></span><br><span class="line">        self.n = array.shape[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># 初始化RI值，用于一致性检验</span></span><br><span class="line">        self.RI_list = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0.52</span>, <span class="number">0.89</span>, <span class="number">1.12</span>, <span class="number">1.26</span>, <span class="number">1.36</span>, <span class="number">1.41</span>, <span class="number">1.46</span>, <span class="number">1.49</span>, <span class="number">1.52</span>, <span class="number">1.54</span>, <span class="number">1.56</span>, <span class="number">1.58</span>,</span><br><span class="line">                        <span class="number">1.59</span>]</span><br><span class="line">        <span class="comment"># 矩阵的特征值和特征向量</span></span><br><span class="line">        self.eig_val, self.eig_vector = np.linalg.eig(self.array)</span><br><span class="line">        <span class="comment"># 矩阵的最大特征值</span></span><br><span class="line">        self.max_eig_val = np.<span class="built_in">max</span>(self.eig_val)</span><br><span class="line">        <span class="comment"># 矩阵最大特征值对应的特征向量</span></span><br><span class="line">        self.max_eig_vector = self.eig_vector[:, np.argmax(self.eig_val)].real</span><br><span class="line">        <span class="comment"># 矩阵的一致性指标CI</span></span><br><span class="line">        self.CI_val = (self.max_eig_val - self.n) / (self.n - <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 矩阵的一致性比例CR</span></span><br><span class="line">        self.CR_val = self.CI_val / (self.RI_list[self.n - <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    一致性判断</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_consist</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 打印矩阵的一致性指标CI和一致性比例CR</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;判断矩阵的CI值为：&quot;</span> + <span class="built_in">str</span>(self.CI_val))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;判断矩阵的CR值为：&quot;</span> + <span class="built_in">str</span>(self.CR_val))</span><br><span class="line">        <span class="comment"># 进行一致性检验判断</span></span><br><span class="line">        <span class="keyword">if</span> self.n == <span class="number">2</span>:  <span class="comment"># 当只有两个子因素的情况</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;仅包含两个子因素，不存在一致性问题&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> self.CR_val &lt; <span class="number">0.1</span>:  <span class="comment"># CR值小于0.1，可以通过一致性检验</span></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;判断矩阵的CR值为&quot;</span> + <span class="built_in">str</span>(self.CR_val) + <span class="string">&quot;,通过一致性检验&quot;</span>)</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">            <span class="keyword">else</span>:  <span class="comment"># CR值大于0.1, 一致性检验不通过</span></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;判断矩阵的CR值为&quot;</span> + <span class="built_in">str</span>(self.CR_val) + <span class="string">&quot;未通过一致性检验&quot;</span>)</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    算术平均法求权重</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">cal_weight_by_arithmetic_method</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 求矩阵的每列的和</span></span><br><span class="line">        col_sum = np.<span class="built_in">sum</span>(self.array, axis=<span class="number">0</span>)</span><br><span class="line">        <span class="comment"># 将判断矩阵按照列归一化</span></span><br><span class="line">        array_normed = self.array / col_sum</span><br><span class="line">        <span class="comment"># 计算权重向量</span></span><br><span class="line">        array_weight = np.<span class="built_in">sum</span>(array_normed, axis=<span class="number">1</span>) / self.n</span><br><span class="line">        <span class="comment"># 打印权重向量</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;算术平均法计算得到的权重向量为：\n&quot;</span>, array_weight)</span><br><span class="line">        <span class="comment"># 返回权重向量的值</span></span><br><span class="line">        <span class="keyword">return</span> array_weight</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    几何平均法求权重</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">cal_weight__by_geometric_method</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 求矩阵的每列的积</span></span><br><span class="line">        col_product = np.product(self.array, axis=<span class="number">0</span>)</span><br><span class="line">        <span class="comment"># 将得到的积向量的每个分量进行开n次方</span></span><br><span class="line">        array_power = np.power(col_product, <span class="number">1</span> / self.n)</span><br><span class="line">        <span class="comment"># 将列向量归一化</span></span><br><span class="line">        array_weight = array_power / np.<span class="built_in">sum</span>(array_power)</span><br><span class="line">        <span class="comment"># 打印权重向量</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;几何平均法计算得到的权重向量为：\n&quot;</span>, array_weight)</span><br><span class="line">        <span class="comment"># 返回权重向量的值</span></span><br><span class="line">        <span class="keyword">return</span> array_weight</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    特征值法求权重</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">cal_weight__by_eigenvalue_method</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 将矩阵最大特征值对应的特征向量进行归一化处理就得到了权重</span></span><br><span class="line">        array_weight = self.max_eig_vector / np.<span class="built_in">sum</span>(self.max_eig_vector)</span><br><span class="line">        <span class="comment"># 打印权重向量</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;特征值法计算得到的权重向量为：\n&quot;</span>, array_weight)</span><br><span class="line">        <span class="comment"># 返回权重向量的值</span></span><br><span class="line">        <span class="keyword">return</span> array_weight</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 给出判断矩阵</span></span><br><span class="line">    b = np.array([[<span class="number">1</span>, <span class="number">1</span> / <span class="number">3</span>, <span class="number">1</span> / <span class="number">8</span>], [<span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span> / <span class="number">3</span>], [<span class="number">8</span>, <span class="number">3</span>, <span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 算术平均法求权重</span></span><br><span class="line">    weight1 = AHP(b).cal_weight_by_arithmetic_method()</span><br><span class="line">    <span class="comment"># 几何平均法求权重</span></span><br><span class="line">    weight2 = AHP(b).cal_weight__by_geometric_method()</span><br><span class="line">    <span class="comment"># 特征值法求权重</span></span><br><span class="line">    weight3 = AHP(b).cal_weight__by_eigenvalue_method()</span><br></pre></td></tr></table></figure>

<h1 id="随机森林分类模型"><a href="#随机森林分类模型" class="headerlink" title="随机森林分类模型"></a>随机森林分类模型</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">随机森林需要调整的参数有：</span></span><br><span class="line"><span class="string">（1）    决策树的个数</span></span><br><span class="line"><span class="string">（2）    特征属性的个数</span></span><br><span class="line"><span class="string">（3）    递归次数（即决策树的深度）</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> inf</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> zeros</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"> </span><br><span class="line"><span class="comment">#生成数据集。数据集包括标签，全包含在返回值的dataset上</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_Datasets</span>():</span><br><span class="line">    <span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_classification</span><br><span class="line">    dataSet,classLabels=make_classification(n_samples=<span class="number">200</span>,n_features=<span class="number">100</span>,n_classes=<span class="number">2</span>)</span><br><span class="line">    <span class="comment">#print(dataSet.shape,classLabels.shape)</span></span><br><span class="line">    <span class="keyword">return</span> np.concatenate((dataSet,classLabels.reshape((-<span class="number">1</span>,<span class="number">1</span>))),axis=<span class="number">1</span>)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="comment">#切分数据集，实现交叉验证。可以利用它来选择决策树个数。但本例没有实现其代码。</span></span><br><span class="line"><span class="comment">#原理如下：</span></span><br><span class="line"><span class="comment">#第一步，将训练集划分为大小相同的K份；</span></span><br><span class="line"><span class="comment">#第二步，我们选择其中的K-1分训练模型，将用余下的那一份计算模型的预测值，</span></span><br><span class="line"><span class="comment">#这一份通常被称为交叉验证集；第三步，我们对所有考虑使用的参数建立模型</span></span><br><span class="line"><span class="comment">#并做出预测，然后使用不同的K值重复这一过程。</span></span><br><span class="line"><span class="comment">#然后是关键，我们利用在不同的K下平均准确率最高所对应的决策树个数</span></span><br><span class="line"><span class="comment">#作为算法决策树个数</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">splitDataSet</span>(<span class="params">dataSet,n_folds</span>):     <span class="comment">#将训练集划分为大小相同的n_folds份；</span></span><br><span class="line">    fold_size=<span class="built_in">len</span>(dataSet)/n_folds</span><br><span class="line">    data_split=[]</span><br><span class="line">    begin=<span class="number">0</span></span><br><span class="line">    end=fold_size</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_folds):</span><br><span class="line">        data_split.append(dataSet[begin:end,:])</span><br><span class="line">        begin=end</span><br><span class="line">        end+=fold_size</span><br><span class="line">    <span class="keyword">return</span> data_split</span><br><span class="line"><span class="comment">#构建n个子集</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_subsamples</span>(<span class="params">dataSet,n</span>):</span><br><span class="line">    subDataSet=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        index=[]     <span class="comment">#每次都重新选择k个 索引</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(dataSet)):  <span class="comment">#长度是k</span></span><br><span class="line">            index.append(np.random.randint(<span class="built_in">len</span>(dataSet)))  <span class="comment">#(0,len(dataSet)) 内的一个整数</span></span><br><span class="line">        subDataSet.append(dataSet[index,:])</span><br><span class="line">    <span class="keyword">return</span> subDataSet</span><br><span class="line"> </span><br><span class="line"><span class="comment">#    subDataSet=get_subsamples(dataSet,10)</span></span><br><span class="line"><span class="comment">#############################################################################</span></span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="comment">#根据某个特征及值对数据进行分类</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">binSplitDataSet</span>(<span class="params">dataSet,feature,value</span>):</span><br><span class="line">    </span><br><span class="line"> </span><br><span class="line">    mat0=dataSet[np.nonzero(dataSet[:,feature]&gt;value)[<span class="number">0</span>],:]</span><br><span class="line">    mat1=dataSet[np.nonzero(dataSet[:,feature]&lt;value)[<span class="number">0</span>],:]</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> mat0,mat1</span><br><span class="line"> </span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  feature=2 </span></span><br><span class="line"><span class="string">  value=1</span></span><br><span class="line"><span class="string">  dataSet=get_Datasets()</span></span><br><span class="line"><span class="string">  mat0,mat1= binSplitDataSet(dataSet,2,1)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">#计算方差，回归时使用</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">regErr</span>(<span class="params">dataSet</span>):</span><br><span class="line">    <span class="keyword">return</span> np.var(dataSet[:,-<span class="number">1</span>])*np.shape(dataSet)[<span class="number">0</span>]</span><br><span class="line"> </span><br><span class="line"><span class="comment">#计算平均值，回归时使用</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">regLeaf</span>(<span class="params">dataSet</span>):</span><br><span class="line">    <span class="keyword">return</span> np.mean(dataSet[:,-<span class="number">1</span>])</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">MostNumber</span>(<span class="params">dataSet</span>):  <span class="comment">#返回多类</span></span><br><span class="line">    <span class="comment">#number=set(dataSet[:,-1])</span></span><br><span class="line">    len0=<span class="built_in">len</span>(np.nonzero(dataSet[:,-<span class="number">1</span>]==<span class="number">0</span>)[<span class="number">0</span>])</span><br><span class="line">    len1=<span class="built_in">len</span>(np.nonzero(dataSet[:,-<span class="number">1</span>]==<span class="number">1</span>)[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">if</span> len0&gt;len1:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="comment">#计算基尼指数   一个随机选中的样本在子集中被分错的可能性   是被选中的概率乘以被分错的概率 </span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gini</span>(<span class="params">dataSet</span>):</span><br><span class="line">    corr=<span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">set</span>(dataSet[:,-<span class="number">1</span>]):           <span class="comment">#i 是这个特征下的 某个特征值</span></span><br><span class="line">        corr+=(<span class="built_in">len</span>(np.nonzero(dataSet[:,-<span class="number">1</span>]==i)[<span class="number">0</span>])/<span class="built_in">len</span>(dataSet))**<span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>-corr</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">select_best_feature</span>(<span class="params">dataSet,m,alpha=<span class="string">&quot;huigui&quot;</span></span>):</span><br><span class="line">    f=dataSet.shape[<span class="number">1</span>]                                            <span class="comment">#拿过这个数据集，看这个数据集有多少个特征，即f个</span></span><br><span class="line">    index=[]</span><br><span class="line">    bestS=inf;</span><br><span class="line">    bestfeature=<span class="number">0</span>;bestValue=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> alpha==<span class="string">&quot;huigui&quot;</span>:</span><br><span class="line">        S=regErr(dataSet)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        S=gini(dataSet)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">        index.append(np.random.randint(f))                        <span class="comment">#在f个特征里随机，注意是随机！选择m个特征，然后在这m个特征里选择一个合适的分类特征。 </span></span><br><span class="line">                                                                  </span><br><span class="line">    <span class="keyword">for</span> feature <span class="keyword">in</span> index:</span><br><span class="line">        <span class="keyword">for</span> splitVal <span class="keyword">in</span> <span class="built_in">set</span>(dataSet[:,feature]):                  <span class="comment">#set() 函数创建一个无序不重复元素集，用于遍历这个特征下所有的值</span></span><br><span class="line">            mat0,mat1=binSplitDataSet(dataSet,feature,splitVal)  </span><br><span class="line">            <span class="keyword">if</span> alpha==<span class="string">&quot;huigui&quot;</span>:  newS=regErr(mat0)+regErr(mat1)   <span class="comment">#计算每个分支的回归方差</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                newS=gini(mat0)+gini(mat1)                        <span class="comment">#计算被分错率</span></span><br><span class="line">            <span class="keyword">if</span> bestS&gt;newS:</span><br><span class="line">                bestfeature=feature</span><br><span class="line">                bestValue=splitVal</span><br><span class="line">                bestS=newS                      </span><br><span class="line">    <span class="keyword">if</span> (S-bestS)&lt;<span class="number">0.001</span> <span class="keyword">and</span> alpha==<span class="string">&quot;huigui&quot;</span>:                      <span class="comment"># 对于回归来说，方差足够了，那就取这个分支的均值</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span>,regLeaf(dataSet)</span><br><span class="line">    <span class="keyword">elif</span> (S-bestS)&lt;<span class="number">0.001</span>:</span><br><span class="line">        <span class="comment">#print(S,bestS)</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span>,MostNumber(dataSet)                          <span class="comment">#对于分类来说，被分错率足够下了，那这个分支的分类就是大多数所在的类。</span></span><br><span class="line">    <span class="comment">#mat0,mat1=binSplitDataSet(dataSet,feature,splitVal)</span></span><br><span class="line">    <span class="keyword">return</span> bestfeature,bestValue</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">createTree</span>(<span class="params">dataSet,alpha=<span class="string">&quot;huigui&quot;</span>,m=<span class="number">20</span>,max_level=<span class="number">10</span></span>):             <span class="comment">#实现决策树，使用20个特征，深度为10，</span></span><br><span class="line">    bestfeature,bestValue=select_best_feature(dataSet,m,alpha=alpha)</span><br><span class="line">    <span class="keyword">if</span> bestfeature==<span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> bestValue</span><br><span class="line">    retTree=&#123;&#125;</span><br><span class="line">    max_level-=<span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> max_level&lt;<span class="number">0</span>:   <span class="comment">#控制深度</span></span><br><span class="line">        <span class="keyword">return</span> regLeaf(dataSet)</span><br><span class="line">    retTree[<span class="string">&#x27;bestFeature&#x27;</span>]=bestfeature</span><br><span class="line">    retTree[<span class="string">&#x27;bestVal&#x27;</span>]=bestValue</span><br><span class="line">    lSet,rSet=binSplitDataSet(dataSet,bestfeature,bestValue)      <span class="comment">#lSet是根据特征bestfeature分到左边的向量，rSet是根据特征bestfeature分到右边的向量</span></span><br><span class="line">    retTree[<span class="string">&#x27;right&#x27;</span>]=createTree(rSet,alpha,m,max_level)</span><br><span class="line">    retTree[<span class="string">&#x27;left&#x27;</span>]=createTree(lSet,alpha,m,max_level)            <span class="comment">#每棵树都是二叉树，往下分类都是一分为二。</span></span><br><span class="line">    <span class="comment">#print(&#x27;retTree:&#x27;,retTree)</span></span><br><span class="line">    <span class="keyword">return</span> retTree</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">RondomForest</span>(<span class="params">dataSet,n,alpha=<span class="string">&quot;huigui&quot;</span></span>):   <span class="comment">#树的个数</span></span><br><span class="line">    <span class="comment">#dataSet=get_Datasets()</span></span><br><span class="line">    Trees=[]        <span class="comment"># 设置一个空树集合</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        X_train, X_test, y_train, y_test = train_test_split(dataSet[:,:-<span class="number">1</span>], dataSet[:,-<span class="number">1</span>], test_size=<span class="number">0.33</span>, random_state=<span class="number">42</span>)</span><br><span class="line">        X_train=np.concatenate((X_train,y_train.reshape((-<span class="number">1</span>,<span class="number">1</span>))),axis=<span class="number">1</span>)</span><br><span class="line">        Trees.append(createTree(X_train,alpha=alpha))</span><br><span class="line">    <span class="keyword">return</span> Trees     <span class="comment"># 生成好多树</span></span><br><span class="line"><span class="comment">##############################################################</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">#预测单个数据样本，重头！！如何利用已经训练好的随机森林对单个样本进行 回归或分类！</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">treeForecast</span>(<span class="params">trees,data,alpha=<span class="string">&quot;huigui&quot;</span></span>):      </span><br><span class="line">    <span class="keyword">if</span> alpha==<span class="string">&quot;huigui&quot;</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(trees,<span class="built_in">dict</span>):                       <span class="comment">#isinstance() 函数来判断一个对象是否是一个已知的类型</span></span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">float</span>(trees)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> data[trees[<span class="string">&#x27;bestFeature&#x27;</span>]]&gt;trees[<span class="string">&#x27;bestVal&#x27;</span>]:      <span class="comment"># 如果数据的这个特征大于阈值，那就调用左支</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">type</span>(trees[<span class="string">&#x27;left&#x27;</span>])==<span class="string">&#x27;float&#x27;</span>:                 <span class="comment">#如果左支已经是节点了，就返回数值。如果左支还是字典结构，那就继续调用， 用此支的特征和特征值进行选支。 </span></span><br><span class="line">                <span class="keyword">return</span> trees[<span class="string">&#x27;left&#x27;</span>]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> treeForecast(trees[<span class="string">&#x27;left&#x27;</span>],data,alpha)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">type</span>(trees[<span class="string">&#x27;right&#x27;</span>])==<span class="string">&#x27;float&#x27;</span>:</span><br><span class="line">                <span class="keyword">return</span> trees[<span class="string">&#x27;right&#x27;</span>]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> treeForecast(trees[<span class="string">&#x27;right&#x27;</span>],data,alpha)   </span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(trees,<span class="built_in">dict</span>):                      <span class="comment">#分类和回归是同一道理</span></span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">int</span>(trees)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> data[trees[<span class="string">&#x27;bestFeature&#x27;</span>]]&gt;trees[<span class="string">&#x27;bestVal&#x27;</span>]:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">type</span>(trees[<span class="string">&#x27;left&#x27;</span>])==<span class="string">&#x27;int&#x27;</span>:</span><br><span class="line">                <span class="keyword">return</span> trees[<span class="string">&#x27;left&#x27;</span>]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> treeForecast(trees[<span class="string">&#x27;left&#x27;</span>],data,alpha)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">type</span>(trees[<span class="string">&#x27;right&#x27;</span>])==<span class="string">&#x27;int&#x27;</span>:</span><br><span class="line">                <span class="keyword">return</span> trees[<span class="string">&#x27;right&#x27;</span>]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> treeForecast(trees[<span class="string">&#x27;right&#x27;</span>],data,alpha)   </span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line"> </span><br><span class="line"><span class="comment">#随机森林 对 数据集打上标签   0、1 或者是 回归值</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">createForeCast</span>(<span class="params">trees,test_dataSet,alpha=<span class="string">&quot;huigui&quot;</span></span>):</span><br><span class="line">    cm=<span class="built_in">len</span>(test_dataSet)                      </span><br><span class="line">    yhat=np.mat(zeros((cm,<span class="number">1</span>)))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(cm):                                     <span class="comment">#</span></span><br><span class="line">        yhat[i,<span class="number">0</span>]=treeForecast(trees,test_dataSet[i,:],alpha)    <span class="comment">#</span></span><br><span class="line">    <span class="keyword">return</span> yhat</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="comment">#随机森林预测</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predictTree</span>(<span class="params">Trees,test_dataSet,alpha=<span class="string">&quot;huigui&quot;</span></span>):      <span class="comment">#trees 是已经训练好的随机森林   调用它！</span></span><br><span class="line">    cm=<span class="built_in">len</span>(test_dataSet)   </span><br><span class="line">    yhat=np.mat(zeros((cm,<span class="number">1</span>)))   </span><br><span class="line">    <span class="keyword">for</span> trees <span class="keyword">in</span> Trees:</span><br><span class="line">        yhat+=createForeCast(trees,test_dataSet,alpha)    <span class="comment">#把每次的预测结果相加</span></span><br><span class="line">    <span class="keyword">if</span> alpha==<span class="string">&quot;huigui&quot;</span>: yhat/=<span class="built_in">len</span>(Trees)            <span class="comment">#如果是回归的话，每棵树的结果应该是回归值，相加后取平均</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(yhat)):                  <span class="comment">#如果是分类的话，每棵树的结果是一个投票向量，相加后，</span></span><br><span class="line">                                                    <span class="comment">#看每类的投票是否超过半数，超过半数就确定为1</span></span><br><span class="line">            <span class="keyword">if</span> yhat[i,<span class="number">0</span>]&gt;<span class="built_in">len</span>(Trees)/<span class="number">2</span>:            </span><br><span class="line">                yhat[i,<span class="number">0</span>]=<span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                yhat[i,<span class="number">0</span>]=<span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> yhat</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span> :</span><br><span class="line">    dataSet=get_Datasets()  </span><br><span class="line">    <span class="built_in">print</span>(dataSet[:,-<span class="number">1</span>].T)                                     <span class="comment">#打印标签，与后面预测值对比  .T其实就是对一个矩阵的转置</span></span><br><span class="line">    RomdomTrees=RondomForest(dataSet,<span class="number">4</span>,alpha=<span class="string">&quot;fenlei&quot;</span>)         <span class="comment">#这里我训练好了 很多树的集合，就组成了随机森林。一会一棵一棵的调用。</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;---------------------RomdomTrees------------------------&quot;</span>)</span><br><span class="line">    <span class="comment">#print(RomdomTrees[0])</span></span><br><span class="line">    test_dataSet=dataSet                               <span class="comment">#得到数据集和标签</span></span><br><span class="line">    yhat=predictTree(RomdomTrees,test_dataSet,alpha=<span class="string">&quot;fenlei&quot;</span>)  <span class="comment"># 调用训练好的那些树。综合结果，得到预测值。</span></span><br><span class="line">    <span class="built_in">print</span>(yhat.T)</span><br><span class="line"><span class="comment">#get_Datasets()</span></span><br><span class="line">    <span class="built_in">print</span>(dataSet[:,-<span class="number">1</span>].T-yhat.T)</span><br></pre></td></tr></table></figure>


    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E7%BC%96%E7%A8%8B/" rel="tag"># 编程</a>
              <a href="/tags/%E5%BB%BA%E6%A8%A1/" rel="tag"># 建模</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2023/08/12/Python-07/" rel="prev" title="Python 07">
                  <i class="fa fa-chevron-left"></i> Python 07
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2023/08/22/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%20%E2%80%94%20%E7%AE%97%E6%B3%95%E9%83%A8%E5%88%86/" rel="next" title="数学建模——算法部分">
                  数学建模——算法部分 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2023</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">彭 斌</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">48k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">2:55</span>
  </span>
</div>

    </div>
  </footer>

  

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  




  <script src="/js/third-party/pace.js"></script>


  





</body>
</html>

<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/clicklove.js"></script>

